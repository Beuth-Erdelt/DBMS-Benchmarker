<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.6.3" />
<title>dbmsbenchmarker.benchmarker API documentation</title>
<meta name="description" content=":Date: 2018-01-03
:Version: 0.9
:Authors: Patrick Erdelt â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dbmsbenchmarker.benchmarker</code></h1>
</header>
<section id="section-intro">
<p>:Date: 2018-01-03
:Version: 0.9
:Authors: Patrick Erdelt</p>
<p>File containing the central class benchmarker().</p>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">&#34;&#34;&#34;
:Date: 2018-01-03
:Version: 0.9
:Authors: Patrick Erdelt

File containing the central class benchmarker().

&#34;&#34;&#34;
from timeit import default_timer as timer
from tabulate import tabulate
import pandas as pd
from tqdm import tqdm
import logging
from os import makedirs, path
import os
import ast
from shutil import copyfile
import datetime
import time
import re
import hashlib
import pickle
import sys
import json
import math
from operator import itemgetter
from collections import Counter
import multiprocessing as mp
from timeit import default_timer
from dbmsbenchmarker import tools, reporter, parameter, monitor



class singleRunInput:
        &#34;&#34;&#34;
        Class for collecting info about a benchmark run
        &#34;&#34;&#34;
        def __init__(self, numRun, queryString, queryConfig):
                self.numRun = numRun
                self.queryString = queryString
                self.queryConfig = queryConfig



class singleRunOutput:
        &#34;&#34;&#34;
        Class for collecting info about a benchmark run
        &#34;&#34;&#34;
        def __init__(self):
                pass



def singleRun(connectiondata, inputConfig, numRuns, connectionname, numQuery, path=None):
        &#34;&#34;&#34;
        Function for running an actual benchmark run

        :param connectiondata: Data about the connection, dict format
        :param inputConfig: Data containing info about the benchmark run
        :param numRun: Number of benchmark run
        :param connectionname: Name of the connection
        :param numQuery: Number of the query, 1...
        :param path: Result path, for optional storing received data
        :return: returns object of class singleRunOutput
        &#34;&#34;&#34;
        import logging
        logger = logging.getLogger()
        logger.setLevel(logging.DEBUG)
        # init list of results
        results = []
        # connect to dbms
        connection = tools.dbms(connectiondata)
        start = default_timer()
        connection.connect()
        end = default_timer()
        durationConnect = 1000.0*(end - start)
        logging.debug((&#34;singleRun batch size %i: &#34; % len(numRuns)))
        logging.debug((&#34;numRun %s: &#34; % (&#34;/&#34;.join([str(i+1) for i in numRuns])))+&#34;connection [ms]: &#34;+str(durationConnect))
        # perform runs for this connection
        for numRun in numRuns:
                workername = &#34;numRun %i: &#34; % (numRun+1)
                queryString = inputConfig[numRun].queryString
                logging.debug(workername+queryString)
                query = tools.query(inputConfig[numRun].queryConfig)
                error = &#34;&#34;
                try:
                        connection.openCursor()
                        start = default_timer()
                        connection.executeQuery(queryString)
                        end = default_timer()
                        durationExecute = 1000.0*(end - start)
                        logging.debug(workername+&#34;execution [ms]: &#34;+str(durationExecute))
                        # transfer
                        data = []
                        size = 0
                        durationTransfer = 0
                        if query.withData:
                                if len(queryString) != 0:
                                        start = default_timer()
                                        data=connection.fetchResult()
                                        end = default_timer()
                                        durationTransfer = 1000.0*(end - start)
                                        logging.debug(workername+&#34;transfer [ms]: &#34;+str(durationTransfer))
                                        #print(data)
                                        data = [[str(item).strip() for item in sublist] for sublist in data]
                                        logging.debug(workername+&#34;Size of result list retrieved: &#34;+str(sys.getsizeof(data))+&#34; bytes&#34;)
                                        if query.result:
                                                data = [[str(item).strip() for item in sublist] for sublist in data]
                                                if query.restrict_precision is not None:
                                                        data = [[round(float(item), int(query.restrict_precision)) if tools.convertToFloat(item) == float else item for item in sublist] for sublist in data]
                                                if query.sorted and len(data) &gt; 0:
                                                        logging.debug(workername+&#34;Begin sorting&#34;)
                                                        data = sorted(data, key=itemgetter(*list(range(0,len(data[0])))))
                                                        logging.debug(workername+&#34;Finished sorting&#34;)
                                        logging.debug(workername+&#34;Size of sorted result list retrieved: &#34;+str(sys.getsizeof(data))+&#34; bytes&#34;)
                                        # convert to dataframe
                                        columnnames = [[i[0].upper() for i in connection.cursor.description]]
                                        df = pd.DataFrame.from_records(data)
                                        if not df.empty:
                                                df.columns = columnnames
                                        size = int(df.memory_usage(index=True).sum())
                                        # store result set for connection and query
                                        storeResultSet = query.storeResultSet
                                        if storeResultSet and numRun==0:
                                                if path is not None:
                                                        if &#39;dataframe&#39; in query.storeResultSetFormat:
                                                                filename = path+&#34;/query_&#34;+str(numQuery)+&#34;_resultset_&#34;+connectionname+&#34;.pickle&#34;
                                                                print(workername+&#34;Store pickle of result set to &#34;+filename)
                                                                f = open(filename, &#34;wb&#34;)
                                                                pickle.dump(df, f)
                                                                f.close()
                                                        if &#39;csv&#39; in query.storeResultSetFormat:
                                                                filename = path+&#34;/query_&#34;+str(numQuery)+&#34;_resultset_&#34;+connectionname+&#34;.csv&#34;
                                                                print(workername+&#34;Store csv of result set to &#34;+filename)
                                                                f = open(filename, &#34;w&#34;)
                                                                f.write(df.to_csv(index_label=False,index=False))
                                                                f.close()
                                        # store (compressed) data for comparison
                                        if query.result == &#39;hash&#39;:
                                                # replace by hash information
                                                columnnames = [[&#39;hash&#39;]]
                                                data = columnnames + [[hashlib.sha224(pickle.dumps(data)).hexdigest()]]
                                                logging.debug(workername+&#34;Compressed by hash&#34;)
                                        elif query.result == &#39;size&#39;:
                                                # replace by size information
                                                columnnames = [[&#39;size&#39;]]
                                                data = columnnames + [[size]]
                                                #data = columnnames + [[sys.getsizeof(data)]]
                                                logging.debug(workername+&#34;Compressed by size&#34;)
                                        else:
                                                columnnames = [[n[0].upper() for n in connection.cursor.description]]
                                                data = columnnames + data
                                        logging.debug(workername+&#34;Size of sorted result list stored: &#34;+str(sys.getsizeof(data))+&#34; bytes&#34;)
                except Exception as e:
                        logging.exception(workername+&#39;Caught an error: %s&#39; % str(e))
                        error = &#39;{workername}: {exception}&#39;.format(workername=workername, exception=e)
                        durationConnect = 0
                        durationExecute = 0
                        durationTransfer = 0
                        data = []
                        size = 0
                finally:
                        connection.closeCursor()
                result = singleRunOutput()
                result.durationConnect = durationConnect
                result.durationExecute = durationExecute
                result.durationTransfer = durationTransfer
                result.error = error
                result.data = data
                result.size = size
                results.append(result)
        connection.disconnect()
        return results



class benchmarker():
        &#34;&#34;&#34;
        Class for running benchmarks
        &#34;&#34;&#34;
        def __init__(self, result_path=None, working=&#39;query&#39;, batch=False, fixedQuery=None, fixedConnection=None, anonymize=False, unanonymize=[], numProcesses=None):
                &#34;&#34;&#34;
                Construct a new &#39;benchmarker&#39; object.
                Allocated the reporters store (always called) and printer (if reports are to be generated).
                A result folder is created if not existing already.

                :param result_path: Path for storing result files. If None is given, a folder is created using time.
                :param working: Process benchmarks query-wise or connection-wise
                :param batch: Script is running in batch mode (more protocol-like output)
                :param fixedQuery: Number of only query to be benchmarked
                :param fixedConnection: Name of only connection to be benchmarked
                :param anonymize: Anonymize all dbms
                :param unanonymize: List of names of connections, which should not be anonymized despite of parameter anonymize
                :param numProcesses: Number of parallel client processes. Global setting, can be overwritten by connection. If None, half of all available processes is taken
                :return: returns nothing
                &#34;&#34;&#34;
                ## connection management:
                # set number of parallel client processes
                self.numProcesses = numProcesses
                if self.numProcesses is None:
                        self.numProcesses = math.ceil(mp.cpu_count()/2)
                else:
                        self.numProcesses = int(self.numProcesses)
                self.runsPerConnection = 4
                self.timeout = None
                # there is no general pool
                self.pool = None
                # printer is first and fixed reporter
                self.reporter = [reporter.printer(self)]
                # store is fixed reporter and cannot be removed
                self.reporterStore = reporter.storer(self)
                # dict of dbms
                self.dbms = {}
                # list of queries
                self.queries = []
                # should benchmarks be overwritten
                self.overwrite = False
                # clear all possibly present benchmarks
                self.clearBenchmarks()
                # should result folder be created
                self.continuing = False
                if result_path is None:
                        self.code = str(round(time.time()))
                        self.path = self.code
                        makedirs(self.path)
                else:
                        if path.isdir(result_path):
                                if path.isfile(result_path+&#39;/queries.config&#39;) and path.isfile(result_path+&#39;/connections.config&#39;):
                                        # result folder exists and contains results
                                        self.code = path.basename(path.normpath(result_path))
                                        self.path = result_path
                                        self.continuing = True
                                else:
                                        # result path is not the result folder
                                        self.code = str(round(time.time()))
                                        self.path = result_path+&#34;/&#34;+self.code
                                        makedirs(self.path)
                        else:
                                logging.exception(&#34;Path does not exist: &#34;+result_path)
                        #self.path = str(int(path))
                logging.debug(&#34;Benchmarking in folder &#34;+self.path)
                # querywise or connectionwise
                self.working = working
                # batch mode, different output
                self.bBatch = batch
                # benchmark only fixed query or connection
                if not fixedQuery is None:
                        fixedQuery = int(fixedQuery)
                self.fixedQuery = fixedQuery
                self.fixedConnection = fixedConnection
                # anonymize dbms
                self.anonymize = anonymize# True or False
                self.unanonymize = unanonymize# Name of connection
        def clearBenchmarks(self):
                &#34;&#34;&#34;
                Clears all benchmark related protocol data.
                Allocates a timer for execution and a timer for data transfer.

                :return: returns nothing
                &#34;&#34;&#34;
                self.protocol = {&#39;query&#39;:{}, &#39;connection&#39;:{}}
                self.timerExecution = tools.timer(&#34;execution&#34;)
                self.timerTransfer = tools.timer(&#34;datatransfer&#34;)
                self.timerConnect = tools.timer(&#34;connection&#34;)
                self.timers = [self.timerExecution, self.timerTransfer, self.timerConnect]
        def getConfig(self,configfolder=None, connectionfile=None, queryfile=None):
                &#34;&#34;&#34;
                Reads all queries and connections from given config files.
                It&#39;s possible to give a name of a folder instead.
                Filenames &#39;connections.config&#39; and &#39;query.config&#39; are assumed then.

                :param configfolder: Name of the folder containing config files
                :param connectionfile: Name of the file containing connection data
                :param queryfile: Name of the file containing query data
                :return: returns nothing
                &#34;&#34;&#34;
                if configfolder is not None:
                        self.getConnectionsFromFile(configfolder+&#39;/connections.config&#39;)
                        self.getQueriesFromFile(configfolder+&#39;/queries.config&#39;)
                else:
                        self.getConnectionsFromFile(connectionfile)
                        self.getQueriesFromFile(queryfile)
        def getQueriesFromFile(self,filename=None):
                &#34;&#34;&#34;
                Reads all queries from a given file in json format and stores them for further usage.
                The file is copied to the result folder if not there already.

                :param filename: Name of the file containing query data
                :return: returns nothing
                &#34;&#34;&#34;
                # If result folder exists: Read from there
                if path.isfile(self.path+&#39;/queries.config&#39;):
                        filename = self.path+&#39;/queries.config&#39;
                # If nothing is given: Try to read from result folder
                if filename is None:
                        filename = self.path+&#39;/queries.config&#39;
                # If not read from result folder: Copy to result folder
                if not filename == self.path+&#39;/queries.config&#39;:
                        if path.isfile(filename):
                                copyfile(filename, self.path+&#39;/queries.config&#39;)
                        else:
                                logging.exception(&#39;Caught an error: Query file not found&#39;)
                                exit()
                with open(filename,&#39;r&#39;) as inf:
                        self.queryconfig = ast.literal_eval(inf.read())
                        self.queries = self.queryconfig[&#34;queries&#34;].copy()
                        if not &#34;name&#34; in self.queryconfig:
                                self.queryconfig[&#34;name&#34;] = &#34;No name&#34;
                        if not &#34;intro&#34; in self.queryconfig:
                                self.queryconfig[&#34;intro&#34;] = &#34;&#34;
                        if not &#34;factor&#34; in self.queryconfig:
                                self.queryconfig[&#34;factor&#34;] = &#34;total&#34;
                        #if &#34;connectionmanagement&#34; in self.queryconfig:
                        #       if &#34;timeout&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                        #               self.timeout = self.queryconfig[&#34;connectionmanagement&#34;][&#34;timeout&#34;]
                        #       if &#34;numProcesses&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                        #               self.numProcesses = self.queryconfig[&#34;connectionmanagement&#34;][&#34;numProcesses&#34;]
                        #       if &#34;runsPerConnection&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                        #               self.runsPerConnection = self.queryconfig[&#34;connectionmanagement&#34;][&#34;runsPerConnection&#34;]
                        if not &#34;reporting&#34; in self.queryconfig:
                                self.queryconfig[&#34;reporting&#34;] = {&#39;resultsetPerQuery&#39;: True, &#39;resultsetPerQueryConnection&#39;: True, &#39;queryparameter&#39;: True}
                for numQuery in range(1, len(self.queries)+1):
                        self.protocol[&#39;query&#39;][str(numQuery)] = {&#39;errors&#39;:{}, &#39;durations&#39;:{}, &#39;duration&#39;:0.0, &#39;start&#39;:&#39;&#39;, &#39;end&#39;:&#39;&#39;, &#39;dataStorage&#39;: [], &#39;resultSets&#39;: {}, &#39;parameter&#39;: [], &#39;sizes&#39;: {}, &#39;starts&#39;: {}, &#39;ends&#39;: {}}
        def cleanProtocol(self, numQuery):
                &#34;&#34;&#34;
                Cleans the protocol for an existing query.
                This is helpful for rerunning a benchmark.

                :param numQuery: Number of query to benchmark
                :return: returns nothing
                &#34;&#34;&#34;
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;] = {}
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;] = []
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;] = []
        def getConnectionsFromFile(self,filename=None):
                &#34;&#34;&#34;
                Reads all connection data from a given file in json format and stores them for further usage.
                The file is copied to the result folder if not there already.

                :param filename: Name of the file containing connection data
                :return: returns nothing
                &#34;&#34;&#34;
                # If result folder exists: Read from there
                if path.isfile(self.path+&#39;/connections.config&#39;):
                        filename = self.path+&#39;/connections.config&#39;
                # If nothing is given: Try to read from result folder
                if filename is None:
                        filename = self.path+&#39;/connections.config&#39;
                # If not read from result folder: Copy to result folder
                if not filename == self.path+&#39;/connections.config&#39;:
                        if path.isfile(filename):
                                copyfile(filename, self.path+&#39;/connections.config&#39;)
                        else:
                                logging.exception(&#39;Caught an error: Connection file not found&#39;)
                                exit()
                # read from file
                with open(filename,&#39;r&#39;) as inf:
                        self.connections = ast.literal_eval(inf.read())
                # add all dbms
                for c in self.connections:
                        if self.anonymize and not c[&#39;name&#39;] in self.unanonymize:
                                # this dbms shoud be anonymized
                                anonymous = True
                        else:
                                anonymous = False
                        self.dbms[c[&#39;name&#39;]] = tools.dbms(c, anonymous)
                #self.connectDBMSAll()
        def connectDBMSAll(self):
                &#34;&#34;&#34;
                Connects to all dbms we have collected connection data of.

                :return: returns nothing
                &#34;&#34;&#34;
                for c in sorted(self.dbms.keys()):
                        self.connectDBMS(c)
        def disconnectDBMSAll(self):
                &#34;&#34;&#34;
                Disconnects to all dbms we have connected to.

                :return: returns nothing
                &#34;&#34;&#34;
                for c in self.dbms:
                        self.disconnectDBMS(c)
        def connectDBMS(self, connectionname):
                &#34;&#34;&#34;
                Connects to one single dbms.

                :param connectionname: Name of the connection we want to establish.
                :return: returns nothing
                &#34;&#34;&#34;
                print(&#34;Connecting to &#34;+connectionname)
                self.dbms[connectionname].connect()
                print(&#34;Connected to &#34;+self.dbms[connectionname].connectiondata[&#39;name&#39;])
        def disconnectDBMS(self, connectionname):
                &#34;&#34;&#34;
                Disconnects from one single dbms.

                :param connectionname: Name of the connection we want to disconnect from.
                :return: returns nothing
                &#34;&#34;&#34;
                logging.debug(&#34;Disconnect from &#34;+connectionname)
                self.dbms[connectionname].disconnect()
        def removeInactiveConnectionsFromDataframe(self, dataframe):
                &#34;&#34;&#34;
                Remove inactive dbms from dataframe.
                Connection names are expected in first column named 0.

                :param dataframe: Dataframe, first column containing names of connections
                :param benchmarker: Benchmarker object for access to config (check for active connections)
                :return: Cleaned dataframe
                &#34;&#34;&#34;
                newdataframe = dataframe
                for index, row in dataframe.iterrows():
                        if not self.dbms[row[0]].connectiondata[&#39;active&#39;]:
                                newdataframe = newdataframe.drop([index], axis=0)
                newdataframe.reset_index(drop=True, inplace=True)
                return newdataframe
        def benchmarksToDataFrame(self, numQuery, timer):
                &#34;&#34;&#34;
                Returns benchmarks of a given query and timer as a DataFrame (rows=dbms, cols=benchmark runs).

                :param numQuery: Number of query
                :param timer: Timer object
                :return: DataFrame of benchmark times
                &#34;&#34;&#34;
                dataframe = timer.toDataFrame(numQuery)
                # remove inactive connections
                dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
                # drop rows of only 0
                dataframe = dataframe[(dataframe.T[1:] != 0).any()]
                # first column to index
                dataframe = dataframe.set_index(dataframe[0].map(tools.dbms.anonymizer))
                dataframe.index.name = &#39;DBMS&#39;
                # drop first column
                dataframe = dataframe.drop(columns=[0])
                return dataframe
        def statsToDataFrame(self, numQuery, timer):
                &#34;&#34;&#34;
                Returns statistics of a given query and timer as a DataFrame (rows=dbms, cols=statisticd).

                :param numQuery: Number of query
                :param timer: Timer object
                :return: DataFrame of benchmark statistics
                &#34;&#34;&#34;
                dataframe = timer.statsToDataFrame(numQuery)
                # remove inactive connections
                dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
                # add factor column
                dataframe = tools.dataframehelper.addFactor(dataframe, self.queryconfig[&#39;factor&#39;])
                return dataframe
        def generateSortedTotalRanking(self):
                &#34;&#34;&#34;
                Returns dataframe (rows=dbms, col=ranking) of total rankings (average ranking all queries and timers).

                :return: DataFrame of rankings
                &#34;&#34;&#34;
                totalRank = {}
                numSuccessfulQueries = 0
                numActiveDBMS = len([d for i,d in self.dbms.items() if d.connectiondata[&#39;active&#39;]])
                for t in self.timers:
                        for numQuery in range(1, len(self.queries)+1):
                                if t.checkForSuccessfulBenchmarks(numQuery):
                                        queryObject = tools.query(self.queries[numQuery-1])
                                        # is timer active for this query?
                                        if not queryObject.timer[t.name][&#39;active&#39;]:
                                                continue
                                        if not queryObject.active:
                                                continue
                                        numSuccessfulQueries = numSuccessfulQueries + 1
                                        # convert to DataFrame
                                        dataframe = self.statsToDataFrame(numQuery, t)
                                        #print(dataframe)
                                        # test if any rows left
                                        if (dataframe[(dataframe.T[1:] != 0).any()]).empty:
                                                continue
                                        rank = {}
                                        for c in self.dbms.keys():
                                                if self.dbms[c].connectiondata[&#39;active&#39;]:
                                                        rank[self.dbms[c].getName()] = numActiveDBMS
                                        i = 1
                                        for name in dataframe.index:
                                                #if self.dbms[name].connectiondata[&#39;active&#39;]:
                                                rank[name] = i
                                                i = i + 1
                                        totalRank = dict(Counter(totalRank)+Counter(rank))
                # generate dict of ranks
                totalRank = {k: (v / numSuccessfulQueries) for k, v in totalRank.items()}
                # generate sorted dict of ranks
                sortedRank = sorted(totalRank.items(), reverse=True, key=lambda kv: kv[1])
                # convert to dataframe
                dataframe = pd.DataFrame.from_records(sortedRank)
                #dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
                dataframe.columns = [&#39;DBMS&#39;, &#39;Average Position&#39;]
                dataframe = dataframe.set_index(&#39;DBMS&#39;)
                #dataframe.index = dataframe.index.map(tools.dbms.anonymizer)
                return dataframe, numSuccessfulQueries
        def getQueryString(self, numQuery, connectionname=None, numRun=0):
                &#34;&#34;&#34;
                Returns query string.
                This might depend on the number of benchmark run and on the connection.

                :param numQuery: Number of query
                :param connectionname: Name of connection
                :param numRun: Number of benchmark run
                :return: String of (SQL) query
                &#34;&#34;&#34;
                q = self.queries[numQuery-1]
                query = tools.query(q)
                queryString = query.query
                #if connectionname is not None and connectionname in query.DBMS:
                if connectionname is not None and len(query.DBMS) &gt; 0:
                        #print(query.DBMS)
                        for c, q in query.DBMS.items():
                                if connectionname.startswith(c):
                                        #queryString = query.DBMS[connectionname]
                                        queryString = q
                # it is a query template
                if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) &gt; 0:
                        bParametrized = True
                        queryTemplate = queryString
                        params = self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;][numRun]
                        queryString = queryTemplate.format(**params)
                else:
                        bParametrized = False
                return queryString
        def runSingleBenchmark(self, numQuery, connectionname, numRun=0):
                &#34;&#34;&#34;
                Runs a single benchmark run.
                This generates the actual query string and sends it to the connected dbms.

                :param numQuery: Number of query
                :param connectionname: Name of connection
                :param numRun: Number of benchmark run
                :return: String of (SQL) query
                &#34;&#34;&#34;
                queryString = self.getQueryString(numQuery, connectionname=connectionname, numRun=numRun)
                inputConfig = [singleRunInput(0, queryString, self.queries[numQuery-1])]
                output = singleRun(self.dbms[connectionname].connectiondata, inputConfig, [0], connectionname, numQuery, None)
                return output
        def runBenchmark(self, numQuery, connectionname):
                &#34;&#34;&#34;
                Performs a benchmark run (fixed query and connection) and stores results.
                This only happens if we haven&#39;t already benchmarked that pair or it is explicitly wished to rerun the benchmark.

                :param numQuery: Number of query to benchmark
                :param connectionname: Name of connection to benchmark
                :return: True if benchmark has been done, False if skipped
                &#34;&#34;&#34;
                # check if benchmark should be done
                if self.timerExecution.checkForSuccessfulBenchmarks(numQuery, connectionname):
                        # benchmark already done
                        if not self.overwrite or (self.fixedQuery is not None and self.fixedQuery != numQuery) or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                                # rerun not this benchmark
                                logging.debug(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; already done&#34;)
                                return False
                        else:
                                # rerun specified
                                print(&#34;Rerun benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname)
                else:
                        # not been done
                        if not (self.fixedQuery is None and self.fixedConnection is None):
                                # only run specific benchmark
                                if (self.fixedQuery is not None and self.fixedQuery != numQuery) or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                                        # not this benchmark
                                        logging.debug(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; not wanted right now&#34;)
                                        return False
                # prepare basic setting
                logging.debug(&#34;Starting benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname)
                self.startBenchmarkingQuery(numQuery)
                q = self.queries[numQuery-1]
                c = connectionname
                # prepare multiprocessing
                logger = mp.log_to_stderr()
                logger.setLevel(logging.INFO)
                # prepare query object
                query = tools.query(q)
                # connection management for parallel connections
                numProcesses = self.numProcesses
                batchsize = self.runsPerConnection
                timeout = self.timeout
                # overwrite by connection
                if &#39;connectionmanagement&#39; in self.dbms[c].connectiondata:
                        connectionmanagement = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;]
                        if(&#39;numProcesses&#39; in connectionmanagement and connectionmanagement[&#39;numProcesses&#39;] != 0):
                                numProcesses = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;numProcesses&#39;]
                        if(&#39;runsPerConnection&#39; in connectionmanagement):# and connectionmanagement[&#39;runsPerConnection&#39;] != 0):
                                # 0=unlimited
                                batchsize = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;runsPerConnection&#39;]
                        if(&#39;timeout&#39; in connectionmanagement):# and connectionmanagement[&#39;timeout&#39;] != 0):
                                # 0=unlimited
                                timeout = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;timeout&#39;]
                if numProcesses == 0:
                        numProcesses = 1
                if timeout == 0:
                        timeout = None
                if batchsize == 0:
                        batchsize = math.ceil(query.numRun/numProcesses)
                numBatches = math.ceil(query.numRun/batchsize)
                runs = list(range(0,query.numRun))
                # dump settings
                print(&#34;runsPerConnection: &#34;+str(batchsize))
                print(&#34;numProcesses: &#34;+str(numProcesses))
                print(&#34;timeout: &#34;+str(timeout))
                # prepare protocol for result data
                if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;]:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = []
                # prepare protocol for errors
                if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;]:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#34;&#34;
                # prepare protocol for duration
                if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;]:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;][c] = 0.0
                # prepare protocol for sizes
                if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;]:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;][c] = 0.0
                # skip query if not active
                if not query.active:
                        print(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; is not active&#34;)
                        # this stores empty values as placeholder - query list is a &#34;list&#34;
                        self.timerExecution.skipTimer(numQuery, query, connectionname)
                        self.timerTransfer.skipTimer(numQuery, query, connectionname)
                        self.timerConnect.skipTimer(numQuery, query, connectionname)
                        self.stopBenchmarkingQuery(numQuery)
                        return False
                # skip connection if not active
                if not self.dbms[c].connectiondata[&#39;active&#39;]:
                        print(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; is not active&#34;)
                        # this stores empty values as placeholder
                        self.timerExecution.skipTimer(numQuery, query, connectionname)
                        self.timerTransfer.skipTimer(numQuery, query, connectionname)
                        self.timerConnect.skipTimer(numQuery, query, connectionname)
                        self.stopBenchmarkingQuery(numQuery)
                        return False
                # do we want to keep result sets? (because of mismatch)
                keepResultsets = False
                # do we want to cancel / abort loop over benchmarks?
                breakLoop = False
                try:
                        # start connecting
                        self.timerExecution.startTimer(numQuery, query, connectionname)
                        self.timerTransfer.startTimer(numQuery, query, connectionname)
                        if not query.withConnect:
                                # we do not benchmark connection time, so we connect directly and once
                                self.timerConnect.skipTimer(numQuery, query, connectionname)
                                self.connectDBMS(c)
                        else:
                                self.timerConnect.startTimer(numQuery, query, connectionname)
                        #queryString = query.query
                        #if c in query.DBMS:
                        #       queryString = query.DBMS[c]
                        #logging.debug(queryString)
                        # it is a query template
                        if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) &gt; 0:
                                #queryTemplate = queryString
                                bParametrized = True
                        else:
                                bParametrized = False
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = []
                        # tqdm does not allow break
                        if self.bBatch:
                                range_runs = range(0, query.numRun)
                        else:
                                range_runs = tqdm(range(0, query.numRun))
                        # prepare input data for processes
                        inputConfig = []
                        for i in range(query.numRun):
                                # replace parameter in query template
                                #if bParametrized:
                                        #params = self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;][i]
                                        #logging.debug(params)
                                        #queryString = queryTemplate.format(**params)
                                queryString = self.getQueryString(numQuery, c, i)
                                logging.debug(queryString)
                                inputConfig.append(singleRunInput(i, queryString, self.queries[numQuery-1]))
                        lists = []
                        # perform required number of warmup and benchmark runs of query
                        durationBenchmark = 0.0
                        start = default_timer()
                        # store start time for query / connection
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;starts&#39;][c] = str(datetime.datetime.now())
                        # pooling
                        if self.pool is not None:
                                multiple_results = [self.pool.apply_async(singleRun, (self.dbms[c].connectiondata, inputConfig, runs[i*batchsize:(i+1)*batchsize], connectionname, numQuery, self.path)) for i in range(numBatches)]
                                lists = [res.get(timeout=timeout) for res in multiple_results]
                                lists = [i for j in lists for i in j]
                        else:
                                with mp.Pool(processes=numProcesses) as pool:
                                        multiple_results = [pool.apply_async(singleRun, (self.dbms[c].connectiondata, inputConfig, runs[i*batchsize:(i+1)*batchsize], connectionname, numQuery, self.path)) for i in range(numBatches)]
                                        lists = [res.get(timeout=timeout) for res in multiple_results]
                                        lists = [i for j in lists for i in j]
                        # store end time for query / connection
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;ends&#39;][c] = str(datetime.datetime.now())
                        #pool.close()
                        #pool.join()
                        #lists = [res.get() for res in multiple_results]
                        end = default_timer()
                        durationBenchmark = 1000.0*(end - start)
                        l_connect = [l.durationConnect for l in lists]
                        l_execute = [l.durationExecute for l in lists]
                        l_transfer = [l.durationTransfer for l in lists]
                        l_error = [l.error for l in lists]
                        l_data = [l.data for l in lists]
                        l_size = [l.size for l in lists]
                        def output(l):
                                print(l)
                                print(len(l))
                                print(min(l))
                                print(max(l))
                                print(sum(l)/len(l))
                        print(&#34;Connect:&#34;)
                        output(l_connect)
                        print(&#34;Execute:&#34;)
                        output(l_execute)
                        print(&#34;Transfer:&#34;)
                        output(l_transfer)
                        print(&#34;Error:&#34;)
                        print(l_error)
                        print(&#34;Size:&#34;)
                        print(l_size)
                        size = int(sum(l_size))
                        print(size)
                        error = &#34;&#34;
                        for i in range(len(l_error)):
                                if len(l_error[i]) &gt; 0:
                                        error = l_error[i]
                                        break
                        print(error)
                        print(&#34;Data:&#34;)
                        print(l_data)
                        self.timerConnect.time_c = l_connect
                        self.timerExecution.time_c = l_execute
                        self.timerTransfer.time_c = l_transfer
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;][c] = size
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;][c] = durationBenchmark
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = error
                        # result set of query / connection
                        # only for comparion
                        # will be dropped if comparison is successful
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = l_data
                        if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c]) == 0:
                                if not bParametrized:
                                        # shall be constant for all runs
                                        for i in range(len(l_data)):
                                                if not l_data[i] == l_data[0]:
                                                        print(&#34;Received data %i:&#34; % i)
                                                        print(l_data[i])
                                                        print(&#34;Received data 0:&#34;)
                                                        print(l_data[0])
                                                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;NumRun &#39;+str(i+1)+&#39;: Received inconsistent result set&#39;
                                                        logging.debug(&#39;Received differing result set&#39;)
                                                        keepResultsets = True
                                                        break
                        if bParametrized:
                                # own data store for each run
                                dataIndex = len(l_data)
                                data = l_data
                        else:
                                # all runs have same data store
                                dataIndex = 1
                                data = [l_data[0]]
                        # store result set for query only
                        # shall be the same for all connections
                        print(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;])
                        if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;]) &lt; dataIndex:
                                self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;].extend(data)
                        else:
                                numRunStorage = len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;])
                                numRunReceived = len(l_data)
                                print(&#34;NumRuns in Storage: &#34;+str(numRunStorage))
                                print(&#34;NumRuns received: &#34;+str(numRunReceived))
                                if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c]) == 0:
                                        print(&#34;NumRuns to compare: &#34;+str(dataIndex))
                                        for i in range(dataIndex):
                                                print(&#34;Stored data #%i:&#34; % i)
                                                print(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;][i])#, floatfmt=&#34;.10f&#34;))
                                                print(&#34;Received data #%i:&#34; % i)
                                                print(l_data[i])
                                                if not l_data[i] == self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;][i]:
                                                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;NumRun &#39;+str(i+1)+&#39;: Received differing result set&#39;
                                                        logging.debug(&#39;Received differing result set&#39;)
                                                        keepResultsets = True
                                                        break
                                                        #raise ValueError(&#39;Received differing result set&#39;)
                except Exception as e:
                        logging.exception(&#39;Caught an error: %s&#39; % str(e))
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;ERROR ({}) - {}&#39;.format(type(e).__name__, e)
                        # store end time for query / connection
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;ends&#39;][c] = str(datetime.datetime.now())
                        # benchmark is 0 due to error
                        self.timerExecution.abortTimerRun()
                        self.timerTransfer.abortTimerRun()
                        if query.withConnect:
                                # we do benchmark connection time, so we connect every run
                                self.timerConnect.abortTimerRun()
                        # this means ignore benchmark for this query/connection due to error
                        self.timerExecution.cancelTimer()
                        self.timerTransfer.cancelTimer()
                        if query.withConnect:
                                # we do benchmark connection time, so we connect every run
                                self.timerConnect.cancelTimer()
                        # this means store results even if error happend
                        #self.timerExecution.abortTimer()
                        #self.timerTransfer.abortTimer()
                        # tqdm does not support break:
                        # https://github.com/tqdm/tqdm/issues/613
                        breakLoop = True
                finally:
                        self.timerExecution.finishTimer()
                        self.timerTransfer.finishTimer()
                        if query.withConnect:
                                # we do benchmark connection time, so we connect every run
                                #self.disconnectDBMS(c)
                                self.timerConnect.finishTimer()
                if not keepResultsets:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = []
                self.stopBenchmarkingQuery(numQuery)
                #if self.dbms[c].hasHardwareMetrics():
                #       metricsReporter = monitor.metrics(self)
                #       metricsReporter.generatePlotForQuery(numQuery)
                return True
        def startBenchmarkingQuery(self, numQuery):
                &#34;&#34;&#34;
                Starts protocol for that specific query.
                Generates parameters.

                :param numQuery: Number of query to benchmark
                :return: returns nothing
                &#34;&#34;&#34;
                if self.protocol[&#39;query&#39;][str(numQuery)][&#39;start&#39;] == &#34;&#34;:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;start&#39;] = str(datetime.datetime.now())
                self.start_query = timer()
                q = self.queries[numQuery-1]
                query = tools.query(q)
                if len(query.parameter) &gt; 0 and len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) == 0:
                        params = parameter.generateParameters(query.parameter, query.numRun)
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;] = params
                print(&#34;Benchmarking Q&#34;+str(numQuery)+&#39;: &#39;+query.title)
        def stopBenchmarkingQuery(self, numQuery):
                &#34;&#34;&#34;
                Writes collected data to protocol for that specific query.

                :param numQuery: Number of query to benchmark
                :return: returns nothing
                &#34;&#34;&#34;
                end_query = timer()
                duration_query = end_query - self.start_query
                # add to protocol
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;duration&#39;] += 1000.0*duration_query
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;end&#39;] = str(datetime.datetime.now())
        def runBenchmarksQuery(self):
                &#34;&#34;&#34;
                Performs querywise benchmark runs.
                Stores results and generates reports immediately after completion of a query (all connections, all runs).

                :return: returns nothing
                &#34;&#34;&#34;
                for numQuery in range(1, len(self.queries)+1):
                        if self.overwrite and not (self.fixedQuery is not None and self.fixedQuery != numQuery):# or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                                # rerun this query
                                self.cleanProtocol(numQuery)
                        for c in sorted(self.dbms.keys()):
                                # run benchmark, current query and connection
                                bBenchmarkDoneForThisQuery = self.runBenchmark(numQuery, c)
                                # if benchmark has been done: store and generate reports
                                if bBenchmarkDoneForThisQuery:
                                        # store results
                                        self.reporterStore.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
                                        if not self.bBatch:
                                                # generate reports
                                                for r in self.reporter:
                                                        r.init()
                                                        r.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
        def runBenchmarksConnection(self):
                &#34;&#34;&#34;
                Performs connectionwise benchmark runs.
                Stores results and generates reports immediately after completion of a query (all runs).

                :return: returns nothing
                &#34;&#34;&#34;
                for c in sorted(self.dbms.keys()):
                        for numQuery in range(1, len(self.queries)+1):
                                bBenchmarkDone = self.runBenchmark(numQuery, c)
                                # if benchmark has been done: store and generate reports
                                if bBenchmarkDone:
                                        # store results
                                        self.reporterStore.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
                                        if not self.bBatch:
                                                # generate reports
                                                for r in self.reporter:
                                                        r.init()
                                                        r.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
        def runBenchmarks(self):
                &#34;&#34;&#34;
                Runs benchmarks or possibly reruns specific benchmarks.
                Generates reports.

                :return: returns nothing
                &#34;&#34;&#34;
                if self.working == &#39;query&#39;:
                        self.runBenchmarksQuery()
                else:
                        self.runBenchmarksConnection()
                if self.bBatch:
                        # generate reports at the end only
                        self.generateReportsAll()
        def readResultfolder(self):
                &#34;&#34;&#34;
                Reads data of previous benchmark from folder.

                :return: returns nothing
                &#34;&#34;&#34;
                self.clearBenchmarks()
                # read from stored results
                logging.debug(&#34;Read from &#34;+self.path)
                self.reporterStore.readProtocol()
                for numQuery,q in enumerate(self.queries):
                        query = tools.query(q)
                        loaded = self.reporterStore.load(query, numQuery+1, [self.timerExecution, self.timerTransfer, self.timerConnect])
                        if not loaded:
                                break
                # show finished benchmarks
                for numQuery,q in enumerate(self.timerExecution.times):
                        logging.debug(&#34;Q&#34;+str(numQuery+1))
                        numConnection = 1
                        #if len(q) &gt; 0:
                        for c, v in q.items():
                                logging.debug(&#34;C&#34;+str(numConnection)+&#34; &#34;+c+&#34;=&#34;+str(len(v))+&#34; runs&#34;)
                                numConnection = numConnection + 1
        def readBenchmarks(self):
                &#34;&#34;&#34;
                Reads data of previous benchmark from folder.
                Generates all reports.

                :return: returns nothing
                &#34;&#34;&#34;
                self.readResultfolder()
                # generate reports
                self.generateReportsAll()
        def generateReportsAll(self):
                &#34;&#34;&#34;
                Generates all reports.

                :return: returns nothing
                &#34;&#34;&#34;
                for r in self.reporter:
                        print(&#34;Report &#34;+type(r).__name__)
                        r.generateAll([self.timerExecution, self.timerTransfer, self.timerConnect])
        def continueBenchmarks(self, overwrite = False):
                &#34;&#34;&#34;
                Reads data of previous benchmark from folder.
                Continues performing missing benchmarks, if not all queries were treated completely.

                :param overwrite: True if existing benchmarks should be overwritten
                :return: returns nothing
                &#34;&#34;&#34;
                self.overwrite = overwrite
                self.readResultfolder()
                self.runBenchmarks()



class inspector(benchmarker):
        &#34;&#34;&#34;
        Class for inspecting done benchmarks
        &#34;&#34;&#34;
        def __init__(self, result_path, code):
                benchmarker.__init__(self,result_path=result_path+&#34;/&#34;+code)
                self.getConfig()
                self.readResultfolder()
                print(&#34;Connections:&#34;)
                for c in self.connections:
                        print(c[&#39;name&#39;])
                print(&#34;Queries:&#34;)
                for i,q in enumerate(self.queries):
                        if &#39;active&#39; in q and q[&#39;active&#39;]:
                                print(str(i)+&#34;: Q&#34;+str(i+1)+&#34; = &#34;+q[&#39;title&#39;])
        def getResultSetCSV(self, query, connection):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_resultset_&#34;+connection+&#34;.csv&#34;
                if os.path.isfile(filename):
                        df = pd.read_csv(filename)
                        return df
                else:
                        print(&#34;No result found&#34;)
        def getResultSetDF(self, query, connection):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_resultset_&#34;+connection+&#34;.pickle&#34;
                if os.path.isfile(filename):
                        f = open(filename, &#34;rb&#34;)
                        result = pickle.load(f)
                        f.close()
                        return result
                else:
                        print(&#34;No result found&#34;)
        def getBenchmarks(self, query):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_execution_dataframe.pickle&#34;
                f = open(filename, &#34;rb&#34;)
                result = pickle.load(f)
                f.close()
                return result
        def getBenchmarksCSV(self, query, timer=&#34;execution&#34;):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_&#34;+timer+&#34;.csv&#34;
                df = pd.read_csv(filename)
                df_t = df.transpose()
                return df_t
        def getStatistics(self, query):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_execution_statistics.pickle&#34;
                f = open(filename, &#34;rb&#34;)
                result = pickle.load(f)
                f.close()
                return result
        def listQueries(self):
                # list of active queries
                qs = tools.findSuccessfulQueriesAllDBMS(self, None, self.timers)[0]
                # index +1 for public addressing
                qs = [q+1 for q in qs]
                return qs
        def listConnections(self):
                # list of active dbms
                cs = [i for i,q in self.dbms.items() if q.connectiondata[&#39;active&#39;]]
                return cs
        def getSumPerTimer(self):
                dataframe, title = tools.dataframehelper.sumPerTimer(self, numQuery=None, timer=self.timers)
                return dataframe, title
        def getProdPerTimer(self):
                dataframe, title = tools.dataframehelper.multiplyPerTimer(self, numQuery=None, timer=self.timers)
                return dataframe, title
        def getTotalTime(self):
                dataframe, title = tools.dataframehelper.totalTimes(self)
                dataframe.loc[&#39;Total&#39;]= dataframe.sum()
                return dataframe, title
        def getError(self, query, connection=None):
                if connection is None:
                        return self.protocol[&#39;query&#39;][str(query)][&#39;errors&#39;]
                else:
                        return self.protocol[&#39;query&#39;][str(query)][&#39;errors&#39;][connection]
        def printErrors(self):
                for numQuery in range(1, len(self.queries)+1):
                        queryObject = tools.query(self.queries[numQuery-1])
                        if not queryObject.active:
                                continue
                        print(&#34;Q&#34;+str(numQuery))
                        print(self.getError(numQuery))
        def printDataStorageSizes(self):
                for numQuery in range(1, len(self.queries)+1):
                        queryObject = tools.query(self.queries[numQuery-1])
                        if not queryObject.active:
                                continue
                        print(&#34;Q&#34;+str(numQuery))
                        print(str(sys.getsizeof(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;]))+&#34; bytes&#34;)
        def readDataStorage(self, query, numRun=0):
                df = pd.DataFrame(self.protocol[&#39;query&#39;][str(query)][&#39;dataStorage&#39;][numRun])
                # set column names
                df.columns = df.iloc[0]
                # remove first row
                df = df[1:]
                return df
        def readResultSet(self, query, connection, numRun=0):
                df = pd.DataFrame(self.protocol[&#39;query&#39;][str(query)][&#39;resultSets&#39;][connection][numRun])
                # set column names
                df.columns = df.iloc[0]
                # remove first row
                df = df[1:]
                return df
        def getQueryObject(self, query):
                return tools.query(self.queries[query-1])
        def runIsolatedQuery(self, connectionname, queryString):
                query = {
                        &#39;numRun&#39;: 1,
                        &#39;withData&#39;: True,
                        &#39;query&#39;: queryString,
                        &#39;timer&#39;:
                        {
                                &#39;datatransfer&#39;:
                                {
                                        &#39;active&#39;: True,
                                        &#39;sorted&#39;: True,
                                        &#39;compare&#39;: &#39;result&#39;,
                                        &#39;store&#39;: &#39;dataframe&#39;,
                                        &#39;precision&#39;: 4,
                                },
                                &#39;connection&#39;:
                                {
                                        &#39;active&#39;: True,
                                }
                        }
                }
                input = singleRunInput(numRun=0, queryString=queryString, queryConfig=query)
                output = singleRun(connectiondata=self.dbms[connectionname].connectiondata,
                        inputConfig=[input],
                        numRuns=[0],
                        connectionname=connectionname,
                        numQuery=0,
                        path=None)
                df = pd.DataFrame.from_records(output.data)
                # set column names
                df.columns = df.iloc[0]
                # remove first row
                df = df[1:]
                output.dataframe = df
                return output
        def runAndStoreIsolatedQuery(self, connectionname, queryString, queryName=None):
                print(connectionname)
                output = self.runSingleQuery(connectionname, queryString)
                df = output.dataframe
                #print(df)
                if queryName is not None:
                        filename = self.path+&#34;query_resultset_&#34;+connectionname+&#34;_&#34;+queryName+&#34;.pickle&#34;
                        print(&#34;Store pickle of result set to &#34;+filename)
                        f = open(filename, &#34;wb&#34;)
                        pickle.dump(df, f)
                        f.close()
                return df
        def getIsolatedBenchmarks(self, connectionname, queryName):
                filename = self.path+&#34;query_resultset_&#34;+connectionname+&#34;_&#34;+queryName+&#34;.pickle&#34;
                f = open(filename, &#34;rb&#34;)
                result = pickle.load(f)
                f.close()
                return result</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dbmsbenchmarker.benchmarker.singleRun"><code class="name flex">
<span>def <span class="ident">singleRun</span></span>(<span>connectiondata, inputConfig, numRuns, connectionname, numQuery, path=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Function for running an actual benchmark run</p>
<p>:param connectiondata: Data about the connection, dict format
:param inputConfig: Data containing info about the benchmark run
:param numRun: Number of benchmark run
:param connectionname: Name of the connection
:param numQuery: Number of the query, 1&hellip;
:param path: Result path, for optional storing received data
:return: returns object of class singleRunOutput</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def singleRun(connectiondata, inputConfig, numRuns, connectionname, numQuery, path=None):
        &#34;&#34;&#34;
        Function for running an actual benchmark run

        :param connectiondata: Data about the connection, dict format
        :param inputConfig: Data containing info about the benchmark run
        :param numRun: Number of benchmark run
        :param connectionname: Name of the connection
        :param numQuery: Number of the query, 1...
        :param path: Result path, for optional storing received data
        :return: returns object of class singleRunOutput
        &#34;&#34;&#34;
        import logging
        logger = logging.getLogger()
        logger.setLevel(logging.DEBUG)
        # init list of results
        results = []
        # connect to dbms
        connection = tools.dbms(connectiondata)
        start = default_timer()
        connection.connect()
        end = default_timer()
        durationConnect = 1000.0*(end - start)
        logging.debug((&#34;singleRun batch size %i: &#34; % len(numRuns)))
        logging.debug((&#34;numRun %s: &#34; % (&#34;/&#34;.join([str(i+1) for i in numRuns])))+&#34;connection [ms]: &#34;+str(durationConnect))
        # perform runs for this connection
        for numRun in numRuns:
                workername = &#34;numRun %i: &#34; % (numRun+1)
                queryString = inputConfig[numRun].queryString
                logging.debug(workername+queryString)
                query = tools.query(inputConfig[numRun].queryConfig)
                error = &#34;&#34;
                try:
                        connection.openCursor()
                        start = default_timer()
                        connection.executeQuery(queryString)
                        end = default_timer()
                        durationExecute = 1000.0*(end - start)
                        logging.debug(workername+&#34;execution [ms]: &#34;+str(durationExecute))
                        # transfer
                        data = []
                        size = 0
                        durationTransfer = 0
                        if query.withData:
                                if len(queryString) != 0:
                                        start = default_timer()
                                        data=connection.fetchResult()
                                        end = default_timer()
                                        durationTransfer = 1000.0*(end - start)
                                        logging.debug(workername+&#34;transfer [ms]: &#34;+str(durationTransfer))
                                        #print(data)
                                        data = [[str(item).strip() for item in sublist] for sublist in data]
                                        logging.debug(workername+&#34;Size of result list retrieved: &#34;+str(sys.getsizeof(data))+&#34; bytes&#34;)
                                        if query.result:
                                                data = [[str(item).strip() for item in sublist] for sublist in data]
                                                if query.restrict_precision is not None:
                                                        data = [[round(float(item), int(query.restrict_precision)) if tools.convertToFloat(item) == float else item for item in sublist] for sublist in data]
                                                if query.sorted and len(data) &gt; 0:
                                                        logging.debug(workername+&#34;Begin sorting&#34;)
                                                        data = sorted(data, key=itemgetter(*list(range(0,len(data[0])))))
                                                        logging.debug(workername+&#34;Finished sorting&#34;)
                                        logging.debug(workername+&#34;Size of sorted result list retrieved: &#34;+str(sys.getsizeof(data))+&#34; bytes&#34;)
                                        # convert to dataframe
                                        columnnames = [[i[0].upper() for i in connection.cursor.description]]
                                        df = pd.DataFrame.from_records(data)
                                        if not df.empty:
                                                df.columns = columnnames
                                        size = int(df.memory_usage(index=True).sum())
                                        # store result set for connection and query
                                        storeResultSet = query.storeResultSet
                                        if storeResultSet and numRun==0:
                                                if path is not None:
                                                        if &#39;dataframe&#39; in query.storeResultSetFormat:
                                                                filename = path+&#34;/query_&#34;+str(numQuery)+&#34;_resultset_&#34;+connectionname+&#34;.pickle&#34;
                                                                print(workername+&#34;Store pickle of result set to &#34;+filename)
                                                                f = open(filename, &#34;wb&#34;)
                                                                pickle.dump(df, f)
                                                                f.close()
                                                        if &#39;csv&#39; in query.storeResultSetFormat:
                                                                filename = path+&#34;/query_&#34;+str(numQuery)+&#34;_resultset_&#34;+connectionname+&#34;.csv&#34;
                                                                print(workername+&#34;Store csv of result set to &#34;+filename)
                                                                f = open(filename, &#34;w&#34;)
                                                                f.write(df.to_csv(index_label=False,index=False))
                                                                f.close()
                                        # store (compressed) data for comparison
                                        if query.result == &#39;hash&#39;:
                                                # replace by hash information
                                                columnnames = [[&#39;hash&#39;]]
                                                data = columnnames + [[hashlib.sha224(pickle.dumps(data)).hexdigest()]]
                                                logging.debug(workername+&#34;Compressed by hash&#34;)
                                        elif query.result == &#39;size&#39;:
                                                # replace by size information
                                                columnnames = [[&#39;size&#39;]]
                                                data = columnnames + [[size]]
                                                #data = columnnames + [[sys.getsizeof(data)]]
                                                logging.debug(workername+&#34;Compressed by size&#34;)
                                        else:
                                                columnnames = [[n[0].upper() for n in connection.cursor.description]]
                                                data = columnnames + data
                                        logging.debug(workername+&#34;Size of sorted result list stored: &#34;+str(sys.getsizeof(data))+&#34; bytes&#34;)
                except Exception as e:
                        logging.exception(workername+&#39;Caught an error: %s&#39; % str(e))
                        error = &#39;{workername}: {exception}&#39;.format(workername=workername, exception=e)
                        durationConnect = 0
                        durationExecute = 0
                        durationTransfer = 0
                        data = []
                        size = 0
                finally:
                        connection.closeCursor()
                result = singleRunOutput()
                result.durationConnect = durationConnect
                result.durationExecute = durationExecute
                result.durationTransfer = durationTransfer
                result.error = error
                result.data = data
                result.size = size
                results.append(result)
        connection.disconnect()
        return results</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dbmsbenchmarker.benchmarker.benchmarker"><code class="flex name class">
<span>class <span class="ident">benchmarker</span></span>
<span>(</span><span>result_path=None, working='query', batch=False, fixedQuery=None, fixedConnection=None, anonymize=False, unanonymize=[], numProcesses=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Class for running benchmarks</p>
<p>Construct a new 'benchmarker' object.
Allocated the reporters store (always called) and printer (if reports are to be generated).
A result folder is created if not existing already.</p>
<p>:param result_path: Path for storing result files. If None is given, a folder is created using time.
:param working: Process benchmarks query-wise or connection-wise
:param batch: Script is running in batch mode (more protocol-like output)
:param fixedQuery: Number of only query to be benchmarked
:param fixedConnection: Name of only connection to be benchmarked
:param anonymize: Anonymize all dbms
:param unanonymize: List of names of connections, which should not be anonymized despite of parameter anonymize
:param numProcesses: Number of parallel client processes. Global setting, can be overwritten by connection. If None, half of all available processes is taken
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class benchmarker():
        &#34;&#34;&#34;
        Class for running benchmarks
        &#34;&#34;&#34;
        def __init__(self, result_path=None, working=&#39;query&#39;, batch=False, fixedQuery=None, fixedConnection=None, anonymize=False, unanonymize=[], numProcesses=None):
                &#34;&#34;&#34;
                Construct a new &#39;benchmarker&#39; object.
                Allocated the reporters store (always called) and printer (if reports are to be generated).
                A result folder is created if not existing already.

                :param result_path: Path for storing result files. If None is given, a folder is created using time.
                :param working: Process benchmarks query-wise or connection-wise
                :param batch: Script is running in batch mode (more protocol-like output)
                :param fixedQuery: Number of only query to be benchmarked
                :param fixedConnection: Name of only connection to be benchmarked
                :param anonymize: Anonymize all dbms
                :param unanonymize: List of names of connections, which should not be anonymized despite of parameter anonymize
                :param numProcesses: Number of parallel client processes. Global setting, can be overwritten by connection. If None, half of all available processes is taken
                :return: returns nothing
                &#34;&#34;&#34;
                ## connection management:
                # set number of parallel client processes
                self.numProcesses = numProcesses
                if self.numProcesses is None:
                        self.numProcesses = math.ceil(mp.cpu_count()/2)
                else:
                        self.numProcesses = int(self.numProcesses)
                self.runsPerConnection = 4
                self.timeout = None
                # there is no general pool
                self.pool = None
                # printer is first and fixed reporter
                self.reporter = [reporter.printer(self)]
                # store is fixed reporter and cannot be removed
                self.reporterStore = reporter.storer(self)
                # dict of dbms
                self.dbms = {}
                # list of queries
                self.queries = []
                # should benchmarks be overwritten
                self.overwrite = False
                # clear all possibly present benchmarks
                self.clearBenchmarks()
                # should result folder be created
                self.continuing = False
                if result_path is None:
                        self.code = str(round(time.time()))
                        self.path = self.code
                        makedirs(self.path)
                else:
                        if path.isdir(result_path):
                                if path.isfile(result_path+&#39;/queries.config&#39;) and path.isfile(result_path+&#39;/connections.config&#39;):
                                        # result folder exists and contains results
                                        self.code = path.basename(path.normpath(result_path))
                                        self.path = result_path
                                        self.continuing = True
                                else:
                                        # result path is not the result folder
                                        self.code = str(round(time.time()))
                                        self.path = result_path+&#34;/&#34;+self.code
                                        makedirs(self.path)
                        else:
                                logging.exception(&#34;Path does not exist: &#34;+result_path)
                        #self.path = str(int(path))
                logging.debug(&#34;Benchmarking in folder &#34;+self.path)
                # querywise or connectionwise
                self.working = working
                # batch mode, different output
                self.bBatch = batch
                # benchmark only fixed query or connection
                if not fixedQuery is None:
                        fixedQuery = int(fixedQuery)
                self.fixedQuery = fixedQuery
                self.fixedConnection = fixedConnection
                # anonymize dbms
                self.anonymize = anonymize# True or False
                self.unanonymize = unanonymize# Name of connection
        def clearBenchmarks(self):
                &#34;&#34;&#34;
                Clears all benchmark related protocol data.
                Allocates a timer for execution and a timer for data transfer.

                :return: returns nothing
                &#34;&#34;&#34;
                self.protocol = {&#39;query&#39;:{}, &#39;connection&#39;:{}}
                self.timerExecution = tools.timer(&#34;execution&#34;)
                self.timerTransfer = tools.timer(&#34;datatransfer&#34;)
                self.timerConnect = tools.timer(&#34;connection&#34;)
                self.timers = [self.timerExecution, self.timerTransfer, self.timerConnect]
        def getConfig(self,configfolder=None, connectionfile=None, queryfile=None):
                &#34;&#34;&#34;
                Reads all queries and connections from given config files.
                It&#39;s possible to give a name of a folder instead.
                Filenames &#39;connections.config&#39; and &#39;query.config&#39; are assumed then.

                :param configfolder: Name of the folder containing config files
                :param connectionfile: Name of the file containing connection data
                :param queryfile: Name of the file containing query data
                :return: returns nothing
                &#34;&#34;&#34;
                if configfolder is not None:
                        self.getConnectionsFromFile(configfolder+&#39;/connections.config&#39;)
                        self.getQueriesFromFile(configfolder+&#39;/queries.config&#39;)
                else:
                        self.getConnectionsFromFile(connectionfile)
                        self.getQueriesFromFile(queryfile)
        def getQueriesFromFile(self,filename=None):
                &#34;&#34;&#34;
                Reads all queries from a given file in json format and stores them for further usage.
                The file is copied to the result folder if not there already.

                :param filename: Name of the file containing query data
                :return: returns nothing
                &#34;&#34;&#34;
                # If result folder exists: Read from there
                if path.isfile(self.path+&#39;/queries.config&#39;):
                        filename = self.path+&#39;/queries.config&#39;
                # If nothing is given: Try to read from result folder
                if filename is None:
                        filename = self.path+&#39;/queries.config&#39;
                # If not read from result folder: Copy to result folder
                if not filename == self.path+&#39;/queries.config&#39;:
                        if path.isfile(filename):
                                copyfile(filename, self.path+&#39;/queries.config&#39;)
                        else:
                                logging.exception(&#39;Caught an error: Query file not found&#39;)
                                exit()
                with open(filename,&#39;r&#39;) as inf:
                        self.queryconfig = ast.literal_eval(inf.read())
                        self.queries = self.queryconfig[&#34;queries&#34;].copy()
                        if not &#34;name&#34; in self.queryconfig:
                                self.queryconfig[&#34;name&#34;] = &#34;No name&#34;
                        if not &#34;intro&#34; in self.queryconfig:
                                self.queryconfig[&#34;intro&#34;] = &#34;&#34;
                        if not &#34;factor&#34; in self.queryconfig:
                                self.queryconfig[&#34;factor&#34;] = &#34;total&#34;
                        #if &#34;connectionmanagement&#34; in self.queryconfig:
                        #       if &#34;timeout&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                        #               self.timeout = self.queryconfig[&#34;connectionmanagement&#34;][&#34;timeout&#34;]
                        #       if &#34;numProcesses&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                        #               self.numProcesses = self.queryconfig[&#34;connectionmanagement&#34;][&#34;numProcesses&#34;]
                        #       if &#34;runsPerConnection&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                        #               self.runsPerConnection = self.queryconfig[&#34;connectionmanagement&#34;][&#34;runsPerConnection&#34;]
                        if not &#34;reporting&#34; in self.queryconfig:
                                self.queryconfig[&#34;reporting&#34;] = {&#39;resultsetPerQuery&#39;: True, &#39;resultsetPerQueryConnection&#39;: True, &#39;queryparameter&#39;: True}
                for numQuery in range(1, len(self.queries)+1):
                        self.protocol[&#39;query&#39;][str(numQuery)] = {&#39;errors&#39;:{}, &#39;durations&#39;:{}, &#39;duration&#39;:0.0, &#39;start&#39;:&#39;&#39;, &#39;end&#39;:&#39;&#39;, &#39;dataStorage&#39;: [], &#39;resultSets&#39;: {}, &#39;parameter&#39;: [], &#39;sizes&#39;: {}, &#39;starts&#39;: {}, &#39;ends&#39;: {}}
        def cleanProtocol(self, numQuery):
                &#34;&#34;&#34;
                Cleans the protocol for an existing query.
                This is helpful for rerunning a benchmark.

                :param numQuery: Number of query to benchmark
                :return: returns nothing
                &#34;&#34;&#34;
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;] = {}
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;] = []
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;] = []
        def getConnectionsFromFile(self,filename=None):
                &#34;&#34;&#34;
                Reads all connection data from a given file in json format and stores them for further usage.
                The file is copied to the result folder if not there already.

                :param filename: Name of the file containing connection data
                :return: returns nothing
                &#34;&#34;&#34;
                # If result folder exists: Read from there
                if path.isfile(self.path+&#39;/connections.config&#39;):
                        filename = self.path+&#39;/connections.config&#39;
                # If nothing is given: Try to read from result folder
                if filename is None:
                        filename = self.path+&#39;/connections.config&#39;
                # If not read from result folder: Copy to result folder
                if not filename == self.path+&#39;/connections.config&#39;:
                        if path.isfile(filename):
                                copyfile(filename, self.path+&#39;/connections.config&#39;)
                        else:
                                logging.exception(&#39;Caught an error: Connection file not found&#39;)
                                exit()
                # read from file
                with open(filename,&#39;r&#39;) as inf:
                        self.connections = ast.literal_eval(inf.read())
                # add all dbms
                for c in self.connections:
                        if self.anonymize and not c[&#39;name&#39;] in self.unanonymize:
                                # this dbms shoud be anonymized
                                anonymous = True
                        else:
                                anonymous = False
                        self.dbms[c[&#39;name&#39;]] = tools.dbms(c, anonymous)
                #self.connectDBMSAll()
        def connectDBMSAll(self):
                &#34;&#34;&#34;
                Connects to all dbms we have collected connection data of.

                :return: returns nothing
                &#34;&#34;&#34;
                for c in sorted(self.dbms.keys()):
                        self.connectDBMS(c)
        def disconnectDBMSAll(self):
                &#34;&#34;&#34;
                Disconnects to all dbms we have connected to.

                :return: returns nothing
                &#34;&#34;&#34;
                for c in self.dbms:
                        self.disconnectDBMS(c)
        def connectDBMS(self, connectionname):
                &#34;&#34;&#34;
                Connects to one single dbms.

                :param connectionname: Name of the connection we want to establish.
                :return: returns nothing
                &#34;&#34;&#34;
                print(&#34;Connecting to &#34;+connectionname)
                self.dbms[connectionname].connect()
                print(&#34;Connected to &#34;+self.dbms[connectionname].connectiondata[&#39;name&#39;])
        def disconnectDBMS(self, connectionname):
                &#34;&#34;&#34;
                Disconnects from one single dbms.

                :param connectionname: Name of the connection we want to disconnect from.
                :return: returns nothing
                &#34;&#34;&#34;
                logging.debug(&#34;Disconnect from &#34;+connectionname)
                self.dbms[connectionname].disconnect()
        def removeInactiveConnectionsFromDataframe(self, dataframe):
                &#34;&#34;&#34;
                Remove inactive dbms from dataframe.
                Connection names are expected in first column named 0.

                :param dataframe: Dataframe, first column containing names of connections
                :param benchmarker: Benchmarker object for access to config (check for active connections)
                :return: Cleaned dataframe
                &#34;&#34;&#34;
                newdataframe = dataframe
                for index, row in dataframe.iterrows():
                        if not self.dbms[row[0]].connectiondata[&#39;active&#39;]:
                                newdataframe = newdataframe.drop([index], axis=0)
                newdataframe.reset_index(drop=True, inplace=True)
                return newdataframe
        def benchmarksToDataFrame(self, numQuery, timer):
                &#34;&#34;&#34;
                Returns benchmarks of a given query and timer as a DataFrame (rows=dbms, cols=benchmark runs).

                :param numQuery: Number of query
                :param timer: Timer object
                :return: DataFrame of benchmark times
                &#34;&#34;&#34;
                dataframe = timer.toDataFrame(numQuery)
                # remove inactive connections
                dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
                # drop rows of only 0
                dataframe = dataframe[(dataframe.T[1:] != 0).any()]
                # first column to index
                dataframe = dataframe.set_index(dataframe[0].map(tools.dbms.anonymizer))
                dataframe.index.name = &#39;DBMS&#39;
                # drop first column
                dataframe = dataframe.drop(columns=[0])
                return dataframe
        def statsToDataFrame(self, numQuery, timer):
                &#34;&#34;&#34;
                Returns statistics of a given query and timer as a DataFrame (rows=dbms, cols=statisticd).

                :param numQuery: Number of query
                :param timer: Timer object
                :return: DataFrame of benchmark statistics
                &#34;&#34;&#34;
                dataframe = timer.statsToDataFrame(numQuery)
                # remove inactive connections
                dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
                # add factor column
                dataframe = tools.dataframehelper.addFactor(dataframe, self.queryconfig[&#39;factor&#39;])
                return dataframe
        def generateSortedTotalRanking(self):
                &#34;&#34;&#34;
                Returns dataframe (rows=dbms, col=ranking) of total rankings (average ranking all queries and timers).

                :return: DataFrame of rankings
                &#34;&#34;&#34;
                totalRank = {}
                numSuccessfulQueries = 0
                numActiveDBMS = len([d for i,d in self.dbms.items() if d.connectiondata[&#39;active&#39;]])
                for t in self.timers:
                        for numQuery in range(1, len(self.queries)+1):
                                if t.checkForSuccessfulBenchmarks(numQuery):
                                        queryObject = tools.query(self.queries[numQuery-1])
                                        # is timer active for this query?
                                        if not queryObject.timer[t.name][&#39;active&#39;]:
                                                continue
                                        if not queryObject.active:
                                                continue
                                        numSuccessfulQueries = numSuccessfulQueries + 1
                                        # convert to DataFrame
                                        dataframe = self.statsToDataFrame(numQuery, t)
                                        #print(dataframe)
                                        # test if any rows left
                                        if (dataframe[(dataframe.T[1:] != 0).any()]).empty:
                                                continue
                                        rank = {}
                                        for c in self.dbms.keys():
                                                if self.dbms[c].connectiondata[&#39;active&#39;]:
                                                        rank[self.dbms[c].getName()] = numActiveDBMS
                                        i = 1
                                        for name in dataframe.index:
                                                #if self.dbms[name].connectiondata[&#39;active&#39;]:
                                                rank[name] = i
                                                i = i + 1
                                        totalRank = dict(Counter(totalRank)+Counter(rank))
                # generate dict of ranks
                totalRank = {k: (v / numSuccessfulQueries) for k, v in totalRank.items()}
                # generate sorted dict of ranks
                sortedRank = sorted(totalRank.items(), reverse=True, key=lambda kv: kv[1])
                # convert to dataframe
                dataframe = pd.DataFrame.from_records(sortedRank)
                #dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
                dataframe.columns = [&#39;DBMS&#39;, &#39;Average Position&#39;]
                dataframe = dataframe.set_index(&#39;DBMS&#39;)
                #dataframe.index = dataframe.index.map(tools.dbms.anonymizer)
                return dataframe, numSuccessfulQueries
        def getQueryString(self, numQuery, connectionname=None, numRun=0):
                &#34;&#34;&#34;
                Returns query string.
                This might depend on the number of benchmark run and on the connection.

                :param numQuery: Number of query
                :param connectionname: Name of connection
                :param numRun: Number of benchmark run
                :return: String of (SQL) query
                &#34;&#34;&#34;
                q = self.queries[numQuery-1]
                query = tools.query(q)
                queryString = query.query
                #if connectionname is not None and connectionname in query.DBMS:
                if connectionname is not None and len(query.DBMS) &gt; 0:
                        #print(query.DBMS)
                        for c, q in query.DBMS.items():
                                if connectionname.startswith(c):
                                        #queryString = query.DBMS[connectionname]
                                        queryString = q
                # it is a query template
                if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) &gt; 0:
                        bParametrized = True
                        queryTemplate = queryString
                        params = self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;][numRun]
                        queryString = queryTemplate.format(**params)
                else:
                        bParametrized = False
                return queryString
        def runSingleBenchmark(self, numQuery, connectionname, numRun=0):
                &#34;&#34;&#34;
                Runs a single benchmark run.
                This generates the actual query string and sends it to the connected dbms.

                :param numQuery: Number of query
                :param connectionname: Name of connection
                :param numRun: Number of benchmark run
                :return: String of (SQL) query
                &#34;&#34;&#34;
                queryString = self.getQueryString(numQuery, connectionname=connectionname, numRun=numRun)
                inputConfig = [singleRunInput(0, queryString, self.queries[numQuery-1])]
                output = singleRun(self.dbms[connectionname].connectiondata, inputConfig, [0], connectionname, numQuery, None)
                return output
        def runBenchmark(self, numQuery, connectionname):
                &#34;&#34;&#34;
                Performs a benchmark run (fixed query and connection) and stores results.
                This only happens if we haven&#39;t already benchmarked that pair or it is explicitly wished to rerun the benchmark.

                :param numQuery: Number of query to benchmark
                :param connectionname: Name of connection to benchmark
                :return: True if benchmark has been done, False if skipped
                &#34;&#34;&#34;
                # check if benchmark should be done
                if self.timerExecution.checkForSuccessfulBenchmarks(numQuery, connectionname):
                        # benchmark already done
                        if not self.overwrite or (self.fixedQuery is not None and self.fixedQuery != numQuery) or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                                # rerun not this benchmark
                                logging.debug(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; already done&#34;)
                                return False
                        else:
                                # rerun specified
                                print(&#34;Rerun benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname)
                else:
                        # not been done
                        if not (self.fixedQuery is None and self.fixedConnection is None):
                                # only run specific benchmark
                                if (self.fixedQuery is not None and self.fixedQuery != numQuery) or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                                        # not this benchmark
                                        logging.debug(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; not wanted right now&#34;)
                                        return False
                # prepare basic setting
                logging.debug(&#34;Starting benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname)
                self.startBenchmarkingQuery(numQuery)
                q = self.queries[numQuery-1]
                c = connectionname
                # prepare multiprocessing
                logger = mp.log_to_stderr()
                logger.setLevel(logging.INFO)
                # prepare query object
                query = tools.query(q)
                # connection management for parallel connections
                numProcesses = self.numProcesses
                batchsize = self.runsPerConnection
                timeout = self.timeout
                # overwrite by connection
                if &#39;connectionmanagement&#39; in self.dbms[c].connectiondata:
                        connectionmanagement = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;]
                        if(&#39;numProcesses&#39; in connectionmanagement and connectionmanagement[&#39;numProcesses&#39;] != 0):
                                numProcesses = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;numProcesses&#39;]
                        if(&#39;runsPerConnection&#39; in connectionmanagement):# and connectionmanagement[&#39;runsPerConnection&#39;] != 0):
                                # 0=unlimited
                                batchsize = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;runsPerConnection&#39;]
                        if(&#39;timeout&#39; in connectionmanagement):# and connectionmanagement[&#39;timeout&#39;] != 0):
                                # 0=unlimited
                                timeout = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;timeout&#39;]
                if numProcesses == 0:
                        numProcesses = 1
                if timeout == 0:
                        timeout = None
                if batchsize == 0:
                        batchsize = math.ceil(query.numRun/numProcesses)
                numBatches = math.ceil(query.numRun/batchsize)
                runs = list(range(0,query.numRun))
                # dump settings
                print(&#34;runsPerConnection: &#34;+str(batchsize))
                print(&#34;numProcesses: &#34;+str(numProcesses))
                print(&#34;timeout: &#34;+str(timeout))
                # prepare protocol for result data
                if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;]:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = []
                # prepare protocol for errors
                if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;]:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#34;&#34;
                # prepare protocol for duration
                if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;]:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;][c] = 0.0
                # prepare protocol for sizes
                if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;]:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;][c] = 0.0
                # skip query if not active
                if not query.active:
                        print(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; is not active&#34;)
                        # this stores empty values as placeholder - query list is a &#34;list&#34;
                        self.timerExecution.skipTimer(numQuery, query, connectionname)
                        self.timerTransfer.skipTimer(numQuery, query, connectionname)
                        self.timerConnect.skipTimer(numQuery, query, connectionname)
                        self.stopBenchmarkingQuery(numQuery)
                        return False
                # skip connection if not active
                if not self.dbms[c].connectiondata[&#39;active&#39;]:
                        print(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; is not active&#34;)
                        # this stores empty values as placeholder
                        self.timerExecution.skipTimer(numQuery, query, connectionname)
                        self.timerTransfer.skipTimer(numQuery, query, connectionname)
                        self.timerConnect.skipTimer(numQuery, query, connectionname)
                        self.stopBenchmarkingQuery(numQuery)
                        return False
                # do we want to keep result sets? (because of mismatch)
                keepResultsets = False
                # do we want to cancel / abort loop over benchmarks?
                breakLoop = False
                try:
                        # start connecting
                        self.timerExecution.startTimer(numQuery, query, connectionname)
                        self.timerTransfer.startTimer(numQuery, query, connectionname)
                        if not query.withConnect:
                                # we do not benchmark connection time, so we connect directly and once
                                self.timerConnect.skipTimer(numQuery, query, connectionname)
                                self.connectDBMS(c)
                        else:
                                self.timerConnect.startTimer(numQuery, query, connectionname)
                        #queryString = query.query
                        #if c in query.DBMS:
                        #       queryString = query.DBMS[c]
                        #logging.debug(queryString)
                        # it is a query template
                        if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) &gt; 0:
                                #queryTemplate = queryString
                                bParametrized = True
                        else:
                                bParametrized = False
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = []
                        # tqdm does not allow break
                        if self.bBatch:
                                range_runs = range(0, query.numRun)
                        else:
                                range_runs = tqdm(range(0, query.numRun))
                        # prepare input data for processes
                        inputConfig = []
                        for i in range(query.numRun):
                                # replace parameter in query template
                                #if bParametrized:
                                        #params = self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;][i]
                                        #logging.debug(params)
                                        #queryString = queryTemplate.format(**params)
                                queryString = self.getQueryString(numQuery, c, i)
                                logging.debug(queryString)
                                inputConfig.append(singleRunInput(i, queryString, self.queries[numQuery-1]))
                        lists = []
                        # perform required number of warmup and benchmark runs of query
                        durationBenchmark = 0.0
                        start = default_timer()
                        # store start time for query / connection
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;starts&#39;][c] = str(datetime.datetime.now())
                        # pooling
                        if self.pool is not None:
                                multiple_results = [self.pool.apply_async(singleRun, (self.dbms[c].connectiondata, inputConfig, runs[i*batchsize:(i+1)*batchsize], connectionname, numQuery, self.path)) for i in range(numBatches)]
                                lists = [res.get(timeout=timeout) for res in multiple_results]
                                lists = [i for j in lists for i in j]
                        else:
                                with mp.Pool(processes=numProcesses) as pool:
                                        multiple_results = [pool.apply_async(singleRun, (self.dbms[c].connectiondata, inputConfig, runs[i*batchsize:(i+1)*batchsize], connectionname, numQuery, self.path)) for i in range(numBatches)]
                                        lists = [res.get(timeout=timeout) for res in multiple_results]
                                        lists = [i for j in lists for i in j]
                        # store end time for query / connection
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;ends&#39;][c] = str(datetime.datetime.now())
                        #pool.close()
                        #pool.join()
                        #lists = [res.get() for res in multiple_results]
                        end = default_timer()
                        durationBenchmark = 1000.0*(end - start)
                        l_connect = [l.durationConnect for l in lists]
                        l_execute = [l.durationExecute for l in lists]
                        l_transfer = [l.durationTransfer for l in lists]
                        l_error = [l.error for l in lists]
                        l_data = [l.data for l in lists]
                        l_size = [l.size for l in lists]
                        def output(l):
                                print(l)
                                print(len(l))
                                print(min(l))
                                print(max(l))
                                print(sum(l)/len(l))
                        print(&#34;Connect:&#34;)
                        output(l_connect)
                        print(&#34;Execute:&#34;)
                        output(l_execute)
                        print(&#34;Transfer:&#34;)
                        output(l_transfer)
                        print(&#34;Error:&#34;)
                        print(l_error)
                        print(&#34;Size:&#34;)
                        print(l_size)
                        size = int(sum(l_size))
                        print(size)
                        error = &#34;&#34;
                        for i in range(len(l_error)):
                                if len(l_error[i]) &gt; 0:
                                        error = l_error[i]
                                        break
                        print(error)
                        print(&#34;Data:&#34;)
                        print(l_data)
                        self.timerConnect.time_c = l_connect
                        self.timerExecution.time_c = l_execute
                        self.timerTransfer.time_c = l_transfer
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;][c] = size
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;][c] = durationBenchmark
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = error
                        # result set of query / connection
                        # only for comparion
                        # will be dropped if comparison is successful
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = l_data
                        if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c]) == 0:
                                if not bParametrized:
                                        # shall be constant for all runs
                                        for i in range(len(l_data)):
                                                if not l_data[i] == l_data[0]:
                                                        print(&#34;Received data %i:&#34; % i)
                                                        print(l_data[i])
                                                        print(&#34;Received data 0:&#34;)
                                                        print(l_data[0])
                                                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;NumRun &#39;+str(i+1)+&#39;: Received inconsistent result set&#39;
                                                        logging.debug(&#39;Received differing result set&#39;)
                                                        keepResultsets = True
                                                        break
                        if bParametrized:
                                # own data store for each run
                                dataIndex = len(l_data)
                                data = l_data
                        else:
                                # all runs have same data store
                                dataIndex = 1
                                data = [l_data[0]]
                        # store result set for query only
                        # shall be the same for all connections
                        print(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;])
                        if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;]) &lt; dataIndex:
                                self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;].extend(data)
                        else:
                                numRunStorage = len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;])
                                numRunReceived = len(l_data)
                                print(&#34;NumRuns in Storage: &#34;+str(numRunStorage))
                                print(&#34;NumRuns received: &#34;+str(numRunReceived))
                                if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c]) == 0:
                                        print(&#34;NumRuns to compare: &#34;+str(dataIndex))
                                        for i in range(dataIndex):
                                                print(&#34;Stored data #%i:&#34; % i)
                                                print(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;][i])#, floatfmt=&#34;.10f&#34;))
                                                print(&#34;Received data #%i:&#34; % i)
                                                print(l_data[i])
                                                if not l_data[i] == self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;][i]:
                                                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;NumRun &#39;+str(i+1)+&#39;: Received differing result set&#39;
                                                        logging.debug(&#39;Received differing result set&#39;)
                                                        keepResultsets = True
                                                        break
                                                        #raise ValueError(&#39;Received differing result set&#39;)
                except Exception as e:
                        logging.exception(&#39;Caught an error: %s&#39; % str(e))
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;ERROR ({}) - {}&#39;.format(type(e).__name__, e)
                        # store end time for query / connection
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;ends&#39;][c] = str(datetime.datetime.now())
                        # benchmark is 0 due to error
                        self.timerExecution.abortTimerRun()
                        self.timerTransfer.abortTimerRun()
                        if query.withConnect:
                                # we do benchmark connection time, so we connect every run
                                self.timerConnect.abortTimerRun()
                        # this means ignore benchmark for this query/connection due to error
                        self.timerExecution.cancelTimer()
                        self.timerTransfer.cancelTimer()
                        if query.withConnect:
                                # we do benchmark connection time, so we connect every run
                                self.timerConnect.cancelTimer()
                        # this means store results even if error happend
                        #self.timerExecution.abortTimer()
                        #self.timerTransfer.abortTimer()
                        # tqdm does not support break:
                        # https://github.com/tqdm/tqdm/issues/613
                        breakLoop = True
                finally:
                        self.timerExecution.finishTimer()
                        self.timerTransfer.finishTimer()
                        if query.withConnect:
                                # we do benchmark connection time, so we connect every run
                                #self.disconnectDBMS(c)
                                self.timerConnect.finishTimer()
                if not keepResultsets:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = []
                self.stopBenchmarkingQuery(numQuery)
                #if self.dbms[c].hasHardwareMetrics():
                #       metricsReporter = monitor.metrics(self)
                #       metricsReporter.generatePlotForQuery(numQuery)
                return True
        def startBenchmarkingQuery(self, numQuery):
                &#34;&#34;&#34;
                Starts protocol for that specific query.
                Generates parameters.

                :param numQuery: Number of query to benchmark
                :return: returns nothing
                &#34;&#34;&#34;
                if self.protocol[&#39;query&#39;][str(numQuery)][&#39;start&#39;] == &#34;&#34;:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;start&#39;] = str(datetime.datetime.now())
                self.start_query = timer()
                q = self.queries[numQuery-1]
                query = tools.query(q)
                if len(query.parameter) &gt; 0 and len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) == 0:
                        params = parameter.generateParameters(query.parameter, query.numRun)
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;] = params
                print(&#34;Benchmarking Q&#34;+str(numQuery)+&#39;: &#39;+query.title)
        def stopBenchmarkingQuery(self, numQuery):
                &#34;&#34;&#34;
                Writes collected data to protocol for that specific query.

                :param numQuery: Number of query to benchmark
                :return: returns nothing
                &#34;&#34;&#34;
                end_query = timer()
                duration_query = end_query - self.start_query
                # add to protocol
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;duration&#39;] += 1000.0*duration_query
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;end&#39;] = str(datetime.datetime.now())
        def runBenchmarksQuery(self):
                &#34;&#34;&#34;
                Performs querywise benchmark runs.
                Stores results and generates reports immediately after completion of a query (all connections, all runs).

                :return: returns nothing
                &#34;&#34;&#34;
                for numQuery in range(1, len(self.queries)+1):
                        if self.overwrite and not (self.fixedQuery is not None and self.fixedQuery != numQuery):# or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                                # rerun this query
                                self.cleanProtocol(numQuery)
                        for c in sorted(self.dbms.keys()):
                                # run benchmark, current query and connection
                                bBenchmarkDoneForThisQuery = self.runBenchmark(numQuery, c)
                                # if benchmark has been done: store and generate reports
                                if bBenchmarkDoneForThisQuery:
                                        # store results
                                        self.reporterStore.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
                                        if not self.bBatch:
                                                # generate reports
                                                for r in self.reporter:
                                                        r.init()
                                                        r.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
        def runBenchmarksConnection(self):
                &#34;&#34;&#34;
                Performs connectionwise benchmark runs.
                Stores results and generates reports immediately after completion of a query (all runs).

                :return: returns nothing
                &#34;&#34;&#34;
                for c in sorted(self.dbms.keys()):
                        for numQuery in range(1, len(self.queries)+1):
                                bBenchmarkDone = self.runBenchmark(numQuery, c)
                                # if benchmark has been done: store and generate reports
                                if bBenchmarkDone:
                                        # store results
                                        self.reporterStore.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
                                        if not self.bBatch:
                                                # generate reports
                                                for r in self.reporter:
                                                        r.init()
                                                        r.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
        def runBenchmarks(self):
                &#34;&#34;&#34;
                Runs benchmarks or possibly reruns specific benchmarks.
                Generates reports.

                :return: returns nothing
                &#34;&#34;&#34;
                if self.working == &#39;query&#39;:
                        self.runBenchmarksQuery()
                else:
                        self.runBenchmarksConnection()
                if self.bBatch:
                        # generate reports at the end only
                        self.generateReportsAll()
        def readResultfolder(self):
                &#34;&#34;&#34;
                Reads data of previous benchmark from folder.

                :return: returns nothing
                &#34;&#34;&#34;
                self.clearBenchmarks()
                # read from stored results
                logging.debug(&#34;Read from &#34;+self.path)
                self.reporterStore.readProtocol()
                for numQuery,q in enumerate(self.queries):
                        query = tools.query(q)
                        loaded = self.reporterStore.load(query, numQuery+1, [self.timerExecution, self.timerTransfer, self.timerConnect])
                        if not loaded:
                                break
                # show finished benchmarks
                for numQuery,q in enumerate(self.timerExecution.times):
                        logging.debug(&#34;Q&#34;+str(numQuery+1))
                        numConnection = 1
                        #if len(q) &gt; 0:
                        for c, v in q.items():
                                logging.debug(&#34;C&#34;+str(numConnection)+&#34; &#34;+c+&#34;=&#34;+str(len(v))+&#34; runs&#34;)
                                numConnection = numConnection + 1
        def readBenchmarks(self):
                &#34;&#34;&#34;
                Reads data of previous benchmark from folder.
                Generates all reports.

                :return: returns nothing
                &#34;&#34;&#34;
                self.readResultfolder()
                # generate reports
                self.generateReportsAll()
        def generateReportsAll(self):
                &#34;&#34;&#34;
                Generates all reports.

                :return: returns nothing
                &#34;&#34;&#34;
                for r in self.reporter:
                        print(&#34;Report &#34;+type(r).__name__)
                        r.generateAll([self.timerExecution, self.timerTransfer, self.timerConnect])
        def continueBenchmarks(self, overwrite = False):
                &#34;&#34;&#34;
                Reads data of previous benchmark from folder.
                Continues performing missing benchmarks, if not all queries were treated completely.

                :param overwrite: True if existing benchmarks should be overwritten
                :return: returns nothing
                &#34;&#34;&#34;
                self.overwrite = overwrite
                self.readResultfolder()
                self.runBenchmarks()</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dbmsbenchmarker.benchmarker.inspector" href="#dbmsbenchmarker.benchmarker.inspector">inspector</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.benchmarksToDataFrame"><code class="name flex">
<span>def <span class="ident">benchmarksToDataFrame</span></span>(<span>self, numQuery, timer)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns benchmarks of a given query and timer as a DataFrame (rows=dbms, cols=benchmark runs).</p>
<p>:param numQuery: Number of query
:param timer: Timer object
:return: DataFrame of benchmark times</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def benchmarksToDataFrame(self, numQuery, timer):
        &#34;&#34;&#34;
        Returns benchmarks of a given query and timer as a DataFrame (rows=dbms, cols=benchmark runs).

        :param numQuery: Number of query
        :param timer: Timer object
        :return: DataFrame of benchmark times
        &#34;&#34;&#34;
        dataframe = timer.toDataFrame(numQuery)
        # remove inactive connections
        dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
        # drop rows of only 0
        dataframe = dataframe[(dataframe.T[1:] != 0).any()]
        # first column to index
        dataframe = dataframe.set_index(dataframe[0].map(tools.dbms.anonymizer))
        dataframe.index.name = &#39;DBMS&#39;
        # drop first column
        dataframe = dataframe.drop(columns=[0])
        return dataframe</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.cleanProtocol"><code class="name flex">
<span>def <span class="ident">cleanProtocol</span></span>(<span>self, numQuery)</span>
</code></dt>
<dd>
<section class="desc"><p>Cleans the protocol for an existing query.
This is helpful for rerunning a benchmark.</p>
<p>:param numQuery: Number of query to benchmark
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def cleanProtocol(self, numQuery):
        &#34;&#34;&#34;
        Cleans the protocol for an existing query.
        This is helpful for rerunning a benchmark.

        :param numQuery: Number of query to benchmark
        :return: returns nothing
        &#34;&#34;&#34;
        self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;] = {}
        self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;] = []
        self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;] = []</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.clearBenchmarks"><code class="name flex">
<span>def <span class="ident">clearBenchmarks</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Clears all benchmark related protocol data.
Allocates a timer for execution and a timer for data transfer.</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def clearBenchmarks(self):
        &#34;&#34;&#34;
        Clears all benchmark related protocol data.
        Allocates a timer for execution and a timer for data transfer.

        :return: returns nothing
        &#34;&#34;&#34;
        self.protocol = {&#39;query&#39;:{}, &#39;connection&#39;:{}}
        self.timerExecution = tools.timer(&#34;execution&#34;)
        self.timerTransfer = tools.timer(&#34;datatransfer&#34;)
        self.timerConnect = tools.timer(&#34;connection&#34;)
        self.timers = [self.timerExecution, self.timerTransfer, self.timerConnect]</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.connectDBMS"><code class="name flex">
<span>def <span class="ident">connectDBMS</span></span>(<span>self, connectionname)</span>
</code></dt>
<dd>
<section class="desc"><p>Connects to one single dbms.</p>
<p>:param connectionname: Name of the connection we want to establish.
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def connectDBMS(self, connectionname):
        &#34;&#34;&#34;
        Connects to one single dbms.

        :param connectionname: Name of the connection we want to establish.
        :return: returns nothing
        &#34;&#34;&#34;
        print(&#34;Connecting to &#34;+connectionname)
        self.dbms[connectionname].connect()
        print(&#34;Connected to &#34;+self.dbms[connectionname].connectiondata[&#39;name&#39;])</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.connectDBMSAll"><code class="name flex">
<span>def <span class="ident">connectDBMSAll</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Connects to all dbms we have collected connection data of.</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def connectDBMSAll(self):
        &#34;&#34;&#34;
        Connects to all dbms we have collected connection data of.

        :return: returns nothing
        &#34;&#34;&#34;
        for c in sorted(self.dbms.keys()):
                self.connectDBMS(c)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.continueBenchmarks"><code class="name flex">
<span>def <span class="ident">continueBenchmarks</span></span>(<span>self, overwrite=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads data of previous benchmark from folder.
Continues performing missing benchmarks, if not all queries were treated completely.</p>
<p>:param overwrite: True if existing benchmarks should be overwritten
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def continueBenchmarks(self, overwrite = False):
        &#34;&#34;&#34;
        Reads data of previous benchmark from folder.
        Continues performing missing benchmarks, if not all queries were treated completely.

        :param overwrite: True if existing benchmarks should be overwritten
        :return: returns nothing
        &#34;&#34;&#34;
        self.overwrite = overwrite
        self.readResultfolder()
        self.runBenchmarks()</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMS"><code class="name flex">
<span>def <span class="ident">disconnectDBMS</span></span>(<span>self, connectionname)</span>
</code></dt>
<dd>
<section class="desc"><p>Disconnects from one single dbms.</p>
<p>:param connectionname: Name of the connection we want to disconnect from.
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def disconnectDBMS(self, connectionname):
        &#34;&#34;&#34;
        Disconnects from one single dbms.

        :param connectionname: Name of the connection we want to disconnect from.
        :return: returns nothing
        &#34;&#34;&#34;
        logging.debug(&#34;Disconnect from &#34;+connectionname)
        self.dbms[connectionname].disconnect()</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMSAll"><code class="name flex">
<span>def <span class="ident">disconnectDBMSAll</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Disconnects to all dbms we have connected to.</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def disconnectDBMSAll(self):
        &#34;&#34;&#34;
        Disconnects to all dbms we have connected to.

        :return: returns nothing
        &#34;&#34;&#34;
        for c in self.dbms:
                self.disconnectDBMS(c)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.generateReportsAll"><code class="name flex">
<span>def <span class="ident">generateReportsAll</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates all reports.</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def generateReportsAll(self):
        &#34;&#34;&#34;
        Generates all reports.

        :return: returns nothing
        &#34;&#34;&#34;
        for r in self.reporter:
                print(&#34;Report &#34;+type(r).__name__)
                r.generateAll([self.timerExecution, self.timerTransfer, self.timerConnect])</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.generateSortedTotalRanking"><code class="name flex">
<span>def <span class="ident">generateSortedTotalRanking</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns dataframe (rows=dbms, col=ranking) of total rankings (average ranking all queries and timers).</p>
<p>:return: DataFrame of rankings</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def generateSortedTotalRanking(self):
        &#34;&#34;&#34;
        Returns dataframe (rows=dbms, col=ranking) of total rankings (average ranking all queries and timers).

        :return: DataFrame of rankings
        &#34;&#34;&#34;
        totalRank = {}
        numSuccessfulQueries = 0
        numActiveDBMS = len([d for i,d in self.dbms.items() if d.connectiondata[&#39;active&#39;]])
        for t in self.timers:
                for numQuery in range(1, len(self.queries)+1):
                        if t.checkForSuccessfulBenchmarks(numQuery):
                                queryObject = tools.query(self.queries[numQuery-1])
                                # is timer active for this query?
                                if not queryObject.timer[t.name][&#39;active&#39;]:
                                        continue
                                if not queryObject.active:
                                        continue
                                numSuccessfulQueries = numSuccessfulQueries + 1
                                # convert to DataFrame
                                dataframe = self.statsToDataFrame(numQuery, t)
                                #print(dataframe)
                                # test if any rows left
                                if (dataframe[(dataframe.T[1:] != 0).any()]).empty:
                                        continue
                                rank = {}
                                for c in self.dbms.keys():
                                        if self.dbms[c].connectiondata[&#39;active&#39;]:
                                                rank[self.dbms[c].getName()] = numActiveDBMS
                                i = 1
                                for name in dataframe.index:
                                        #if self.dbms[name].connectiondata[&#39;active&#39;]:
                                        rank[name] = i
                                        i = i + 1
                                totalRank = dict(Counter(totalRank)+Counter(rank))
        # generate dict of ranks
        totalRank = {k: (v / numSuccessfulQueries) for k, v in totalRank.items()}
        # generate sorted dict of ranks
        sortedRank = sorted(totalRank.items(), reverse=True, key=lambda kv: kv[1])
        # convert to dataframe
        dataframe = pd.DataFrame.from_records(sortedRank)
        #dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
        dataframe.columns = [&#39;DBMS&#39;, &#39;Average Position&#39;]
        dataframe = dataframe.set_index(&#39;DBMS&#39;)
        #dataframe.index = dataframe.index.map(tools.dbms.anonymizer)
        return dataframe, numSuccessfulQueries</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.getConfig"><code class="name flex">
<span>def <span class="ident">getConfig</span></span>(<span>self, configfolder=None, connectionfile=None, queryfile=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads all queries and connections from given config files.
It's possible to give a name of a folder instead.
Filenames 'connections.config' and 'query.config' are assumed then.</p>
<p>:param configfolder: Name of the folder containing config files
:param connectionfile: Name of the file containing connection data
:param queryfile: Name of the file containing query data
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getConfig(self,configfolder=None, connectionfile=None, queryfile=None):
        &#34;&#34;&#34;
        Reads all queries and connections from given config files.
        It&#39;s possible to give a name of a folder instead.
        Filenames &#39;connections.config&#39; and &#39;query.config&#39; are assumed then.

        :param configfolder: Name of the folder containing config files
        :param connectionfile: Name of the file containing connection data
        :param queryfile: Name of the file containing query data
        :return: returns nothing
        &#34;&#34;&#34;
        if configfolder is not None:
                self.getConnectionsFromFile(configfolder+&#39;/connections.config&#39;)
                self.getQueriesFromFile(configfolder+&#39;/queries.config&#39;)
        else:
                self.getConnectionsFromFile(connectionfile)
                self.getQueriesFromFile(queryfile)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.getConnectionsFromFile"><code class="name flex">
<span>def <span class="ident">getConnectionsFromFile</span></span>(<span>self, filename=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads all connection data from a given file in json format and stores them for further usage.
The file is copied to the result folder if not there already.</p>
<p>:param filename: Name of the file containing connection data
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getConnectionsFromFile(self,filename=None):
        &#34;&#34;&#34;
        Reads all connection data from a given file in json format and stores them for further usage.
        The file is copied to the result folder if not there already.

        :param filename: Name of the file containing connection data
        :return: returns nothing
        &#34;&#34;&#34;
        # If result folder exists: Read from there
        if path.isfile(self.path+&#39;/connections.config&#39;):
                filename = self.path+&#39;/connections.config&#39;
        # If nothing is given: Try to read from result folder
        if filename is None:
                filename = self.path+&#39;/connections.config&#39;
        # If not read from result folder: Copy to result folder
        if not filename == self.path+&#39;/connections.config&#39;:
                if path.isfile(filename):
                        copyfile(filename, self.path+&#39;/connections.config&#39;)
                else:
                        logging.exception(&#39;Caught an error: Connection file not found&#39;)
                        exit()
        # read from file
        with open(filename,&#39;r&#39;) as inf:
                self.connections = ast.literal_eval(inf.read())
        # add all dbms
        for c in self.connections:
                if self.anonymize and not c[&#39;name&#39;] in self.unanonymize:
                        # this dbms shoud be anonymized
                        anonymous = True
                else:
                        anonymous = False
                self.dbms[c[&#39;name&#39;]] = tools.dbms(c, anonymous)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.getQueriesFromFile"><code class="name flex">
<span>def <span class="ident">getQueriesFromFile</span></span>(<span>self, filename=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads all queries from a given file in json format and stores them for further usage.
The file is copied to the result folder if not there already.</p>
<p>:param filename: Name of the file containing query data
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getQueriesFromFile(self,filename=None):
        &#34;&#34;&#34;
        Reads all queries from a given file in json format and stores them for further usage.
        The file is copied to the result folder if not there already.

        :param filename: Name of the file containing query data
        :return: returns nothing
        &#34;&#34;&#34;
        # If result folder exists: Read from there
        if path.isfile(self.path+&#39;/queries.config&#39;):
                filename = self.path+&#39;/queries.config&#39;
        # If nothing is given: Try to read from result folder
        if filename is None:
                filename = self.path+&#39;/queries.config&#39;
        # If not read from result folder: Copy to result folder
        if not filename == self.path+&#39;/queries.config&#39;:
                if path.isfile(filename):
                        copyfile(filename, self.path+&#39;/queries.config&#39;)
                else:
                        logging.exception(&#39;Caught an error: Query file not found&#39;)
                        exit()
        with open(filename,&#39;r&#39;) as inf:
                self.queryconfig = ast.literal_eval(inf.read())
                self.queries = self.queryconfig[&#34;queries&#34;].copy()
                if not &#34;name&#34; in self.queryconfig:
                        self.queryconfig[&#34;name&#34;] = &#34;No name&#34;
                if not &#34;intro&#34; in self.queryconfig:
                        self.queryconfig[&#34;intro&#34;] = &#34;&#34;
                if not &#34;factor&#34; in self.queryconfig:
                        self.queryconfig[&#34;factor&#34;] = &#34;total&#34;
                #if &#34;connectionmanagement&#34; in self.queryconfig:
                #       if &#34;timeout&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                #               self.timeout = self.queryconfig[&#34;connectionmanagement&#34;][&#34;timeout&#34;]
                #       if &#34;numProcesses&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                #               self.numProcesses = self.queryconfig[&#34;connectionmanagement&#34;][&#34;numProcesses&#34;]
                #       if &#34;runsPerConnection&#34; in self.queryconfig[&#34;connectionmanagement&#34;]:
                #               self.runsPerConnection = self.queryconfig[&#34;connectionmanagement&#34;][&#34;runsPerConnection&#34;]
                if not &#34;reporting&#34; in self.queryconfig:
                        self.queryconfig[&#34;reporting&#34;] = {&#39;resultsetPerQuery&#39;: True, &#39;resultsetPerQueryConnection&#39;: True, &#39;queryparameter&#39;: True}
        for numQuery in range(1, len(self.queries)+1):
                self.protocol[&#39;query&#39;][str(numQuery)] = {&#39;errors&#39;:{}, &#39;durations&#39;:{}, &#39;duration&#39;:0.0, &#39;start&#39;:&#39;&#39;, &#39;end&#39;:&#39;&#39;, &#39;dataStorage&#39;: [], &#39;resultSets&#39;: {}, &#39;parameter&#39;: [], &#39;sizes&#39;: {}, &#39;starts&#39;: {}, &#39;ends&#39;: {}}</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.getQueryString"><code class="name flex">
<span>def <span class="ident">getQueryString</span></span>(<span>self, numQuery, connectionname=None, numRun=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns query string.
This might depend on the number of benchmark run and on the connection.</p>
<p>:param numQuery: Number of query
:param connectionname: Name of connection
:param numRun: Number of benchmark run
:return: String of (SQL) query</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getQueryString(self, numQuery, connectionname=None, numRun=0):
        &#34;&#34;&#34;
        Returns query string.
        This might depend on the number of benchmark run and on the connection.

        :param numQuery: Number of query
        :param connectionname: Name of connection
        :param numRun: Number of benchmark run
        :return: String of (SQL) query
        &#34;&#34;&#34;
        q = self.queries[numQuery-1]
        query = tools.query(q)
        queryString = query.query
        #if connectionname is not None and connectionname in query.DBMS:
        if connectionname is not None and len(query.DBMS) &gt; 0:
                #print(query.DBMS)
                for c, q in query.DBMS.items():
                        if connectionname.startswith(c):
                                #queryString = query.DBMS[connectionname]
                                queryString = q
        # it is a query template
        if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) &gt; 0:
                bParametrized = True
                queryTemplate = queryString
                params = self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;][numRun]
                queryString = queryTemplate.format(**params)
        else:
                bParametrized = False
        return queryString</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.readBenchmarks"><code class="name flex">
<span>def <span class="ident">readBenchmarks</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads data of previous benchmark from folder.
Generates all reports.</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def readBenchmarks(self):
        &#34;&#34;&#34;
        Reads data of previous benchmark from folder.
        Generates all reports.

        :return: returns nothing
        &#34;&#34;&#34;
        self.readResultfolder()
        # generate reports
        self.generateReportsAll()</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.readResultfolder"><code class="name flex">
<span>def <span class="ident">readResultfolder</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads data of previous benchmark from folder.</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def readResultfolder(self):
        &#34;&#34;&#34;
        Reads data of previous benchmark from folder.

        :return: returns nothing
        &#34;&#34;&#34;
        self.clearBenchmarks()
        # read from stored results
        logging.debug(&#34;Read from &#34;+self.path)
        self.reporterStore.readProtocol()
        for numQuery,q in enumerate(self.queries):
                query = tools.query(q)
                loaded = self.reporterStore.load(query, numQuery+1, [self.timerExecution, self.timerTransfer, self.timerConnect])
                if not loaded:
                        break
        # show finished benchmarks
        for numQuery,q in enumerate(self.timerExecution.times):
                logging.debug(&#34;Q&#34;+str(numQuery+1))
                numConnection = 1
                #if len(q) &gt; 0:
                for c, v in q.items():
                        logging.debug(&#34;C&#34;+str(numConnection)+&#34; &#34;+c+&#34;=&#34;+str(len(v))+&#34; runs&#34;)
                        numConnection = numConnection + 1</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.removeInactiveConnectionsFromDataframe"><code class="name flex">
<span>def <span class="ident">removeInactiveConnectionsFromDataframe</span></span>(<span>self, dataframe)</span>
</code></dt>
<dd>
<section class="desc"><p>Remove inactive dbms from dataframe.
Connection names are expected in first column named 0.</p>
<p>:param dataframe: Dataframe, first column containing names of connections
:param benchmarker: Benchmarker object for access to config (check for active connections)
:return: Cleaned dataframe</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def removeInactiveConnectionsFromDataframe(self, dataframe):
        &#34;&#34;&#34;
        Remove inactive dbms from dataframe.
        Connection names are expected in first column named 0.

        :param dataframe: Dataframe, first column containing names of connections
        :param benchmarker: Benchmarker object for access to config (check for active connections)
        :return: Cleaned dataframe
        &#34;&#34;&#34;
        newdataframe = dataframe
        for index, row in dataframe.iterrows():
                if not self.dbms[row[0]].connectiondata[&#39;active&#39;]:
                        newdataframe = newdataframe.drop([index], axis=0)
        newdataframe.reset_index(drop=True, inplace=True)
        return newdataframe</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.runBenchmark"><code class="name flex">
<span>def <span class="ident">runBenchmark</span></span>(<span>self, numQuery, connectionname)</span>
</code></dt>
<dd>
<section class="desc"><p>Performs a benchmark run (fixed query and connection) and stores results.
This only happens if we haven't already benchmarked that pair or it is explicitly wished to rerun the benchmark.</p>
<p>:param numQuery: Number of query to benchmark
:param connectionname: Name of connection to benchmark
:return: True if benchmark has been done, False if skipped</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def runBenchmark(self, numQuery, connectionname):
        &#34;&#34;&#34;
        Performs a benchmark run (fixed query and connection) and stores results.
        This only happens if we haven&#39;t already benchmarked that pair or it is explicitly wished to rerun the benchmark.

        :param numQuery: Number of query to benchmark
        :param connectionname: Name of connection to benchmark
        :return: True if benchmark has been done, False if skipped
        &#34;&#34;&#34;
        # check if benchmark should be done
        if self.timerExecution.checkForSuccessfulBenchmarks(numQuery, connectionname):
                # benchmark already done
                if not self.overwrite or (self.fixedQuery is not None and self.fixedQuery != numQuery) or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                        # rerun not this benchmark
                        logging.debug(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; already done&#34;)
                        return False
                else:
                        # rerun specified
                        print(&#34;Rerun benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname)
        else:
                # not been done
                if not (self.fixedQuery is None and self.fixedConnection is None):
                        # only run specific benchmark
                        if (self.fixedQuery is not None and self.fixedQuery != numQuery) or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                                # not this benchmark
                                logging.debug(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; not wanted right now&#34;)
                                return False
        # prepare basic setting
        logging.debug(&#34;Starting benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname)
        self.startBenchmarkingQuery(numQuery)
        q = self.queries[numQuery-1]
        c = connectionname
        # prepare multiprocessing
        logger = mp.log_to_stderr()
        logger.setLevel(logging.INFO)
        # prepare query object
        query = tools.query(q)
        # connection management for parallel connections
        numProcesses = self.numProcesses
        batchsize = self.runsPerConnection
        timeout = self.timeout
        # overwrite by connection
        if &#39;connectionmanagement&#39; in self.dbms[c].connectiondata:
                connectionmanagement = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;]
                if(&#39;numProcesses&#39; in connectionmanagement and connectionmanagement[&#39;numProcesses&#39;] != 0):
                        numProcesses = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;numProcesses&#39;]
                if(&#39;runsPerConnection&#39; in connectionmanagement):# and connectionmanagement[&#39;runsPerConnection&#39;] != 0):
                        # 0=unlimited
                        batchsize = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;runsPerConnection&#39;]
                if(&#39;timeout&#39; in connectionmanagement):# and connectionmanagement[&#39;timeout&#39;] != 0):
                        # 0=unlimited
                        timeout = self.dbms[c].connectiondata[&#39;connectionmanagement&#39;][&#39;timeout&#39;]
        if numProcesses == 0:
                numProcesses = 1
        if timeout == 0:
                timeout = None
        if batchsize == 0:
                batchsize = math.ceil(query.numRun/numProcesses)
        numBatches = math.ceil(query.numRun/batchsize)
        runs = list(range(0,query.numRun))
        # dump settings
        print(&#34;runsPerConnection: &#34;+str(batchsize))
        print(&#34;numProcesses: &#34;+str(numProcesses))
        print(&#34;timeout: &#34;+str(timeout))
        # prepare protocol for result data
        if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;]:
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = []
        # prepare protocol for errors
        if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;]:
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#34;&#34;
        # prepare protocol for duration
        if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;]:
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;][c] = 0.0
        # prepare protocol for sizes
        if c not in self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;]:
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;][c] = 0.0
        # skip query if not active
        if not query.active:
                print(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; is not active&#34;)
                # this stores empty values as placeholder - query list is a &#34;list&#34;
                self.timerExecution.skipTimer(numQuery, query, connectionname)
                self.timerTransfer.skipTimer(numQuery, query, connectionname)
                self.timerConnect.skipTimer(numQuery, query, connectionname)
                self.stopBenchmarkingQuery(numQuery)
                return False
        # skip connection if not active
        if not self.dbms[c].connectiondata[&#39;active&#39;]:
                print(&#34;Benchmarks of Q&#34;+str(numQuery)+&#34; at dbms &#34;+connectionname+&#34; is not active&#34;)
                # this stores empty values as placeholder
                self.timerExecution.skipTimer(numQuery, query, connectionname)
                self.timerTransfer.skipTimer(numQuery, query, connectionname)
                self.timerConnect.skipTimer(numQuery, query, connectionname)
                self.stopBenchmarkingQuery(numQuery)
                return False
        # do we want to keep result sets? (because of mismatch)
        keepResultsets = False
        # do we want to cancel / abort loop over benchmarks?
        breakLoop = False
        try:
                # start connecting
                self.timerExecution.startTimer(numQuery, query, connectionname)
                self.timerTransfer.startTimer(numQuery, query, connectionname)
                if not query.withConnect:
                        # we do not benchmark connection time, so we connect directly and once
                        self.timerConnect.skipTimer(numQuery, query, connectionname)
                        self.connectDBMS(c)
                else:
                        self.timerConnect.startTimer(numQuery, query, connectionname)
                #queryString = query.query
                #if c in query.DBMS:
                #       queryString = query.DBMS[c]
                #logging.debug(queryString)
                # it is a query template
                if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) &gt; 0:
                        #queryTemplate = queryString
                        bParametrized = True
                else:
                        bParametrized = False
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = []
                # tqdm does not allow break
                if self.bBatch:
                        range_runs = range(0, query.numRun)
                else:
                        range_runs = tqdm(range(0, query.numRun))
                # prepare input data for processes
                inputConfig = []
                for i in range(query.numRun):
                        # replace parameter in query template
                        #if bParametrized:
                                #params = self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;][i]
                                #logging.debug(params)
                                #queryString = queryTemplate.format(**params)
                        queryString = self.getQueryString(numQuery, c, i)
                        logging.debug(queryString)
                        inputConfig.append(singleRunInput(i, queryString, self.queries[numQuery-1]))
                lists = []
                # perform required number of warmup and benchmark runs of query
                durationBenchmark = 0.0
                start = default_timer()
                # store start time for query / connection
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;starts&#39;][c] = str(datetime.datetime.now())
                # pooling
                if self.pool is not None:
                        multiple_results = [self.pool.apply_async(singleRun, (self.dbms[c].connectiondata, inputConfig, runs[i*batchsize:(i+1)*batchsize], connectionname, numQuery, self.path)) for i in range(numBatches)]
                        lists = [res.get(timeout=timeout) for res in multiple_results]
                        lists = [i for j in lists for i in j]
                else:
                        with mp.Pool(processes=numProcesses) as pool:
                                multiple_results = [pool.apply_async(singleRun, (self.dbms[c].connectiondata, inputConfig, runs[i*batchsize:(i+1)*batchsize], connectionname, numQuery, self.path)) for i in range(numBatches)]
                                lists = [res.get(timeout=timeout) for res in multiple_results]
                                lists = [i for j in lists for i in j]
                # store end time for query / connection
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;ends&#39;][c] = str(datetime.datetime.now())
                #pool.close()
                #pool.join()
                #lists = [res.get() for res in multiple_results]
                end = default_timer()
                durationBenchmark = 1000.0*(end - start)
                l_connect = [l.durationConnect for l in lists]
                l_execute = [l.durationExecute for l in lists]
                l_transfer = [l.durationTransfer for l in lists]
                l_error = [l.error for l in lists]
                l_data = [l.data for l in lists]
                l_size = [l.size for l in lists]
                def output(l):
                        print(l)
                        print(len(l))
                        print(min(l))
                        print(max(l))
                        print(sum(l)/len(l))
                print(&#34;Connect:&#34;)
                output(l_connect)
                print(&#34;Execute:&#34;)
                output(l_execute)
                print(&#34;Transfer:&#34;)
                output(l_transfer)
                print(&#34;Error:&#34;)
                print(l_error)
                print(&#34;Size:&#34;)
                print(l_size)
                size = int(sum(l_size))
                print(size)
                error = &#34;&#34;
                for i in range(len(l_error)):
                        if len(l_error[i]) &gt; 0:
                                error = l_error[i]
                                break
                print(error)
                print(&#34;Data:&#34;)
                print(l_data)
                self.timerConnect.time_c = l_connect
                self.timerExecution.time_c = l_execute
                self.timerTransfer.time_c = l_transfer
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;sizes&#39;][c] = size
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;durations&#39;][c] = durationBenchmark
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = error
                # result set of query / connection
                # only for comparion
                # will be dropped if comparison is successful
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = l_data
                if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c]) == 0:
                        if not bParametrized:
                                # shall be constant for all runs
                                for i in range(len(l_data)):
                                        if not l_data[i] == l_data[0]:
                                                print(&#34;Received data %i:&#34; % i)
                                                print(l_data[i])
                                                print(&#34;Received data 0:&#34;)
                                                print(l_data[0])
                                                self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;NumRun &#39;+str(i+1)+&#39;: Received inconsistent result set&#39;
                                                logging.debug(&#39;Received differing result set&#39;)
                                                keepResultsets = True
                                                break
                if bParametrized:
                        # own data store for each run
                        dataIndex = len(l_data)
                        data = l_data
                else:
                        # all runs have same data store
                        dataIndex = 1
                        data = [l_data[0]]
                # store result set for query only
                # shall be the same for all connections
                print(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;])
                if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;]) &lt; dataIndex:
                        self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;].extend(data)
                else:
                        numRunStorage = len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;])
                        numRunReceived = len(l_data)
                        print(&#34;NumRuns in Storage: &#34;+str(numRunStorage))
                        print(&#34;NumRuns received: &#34;+str(numRunReceived))
                        if len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c]) == 0:
                                print(&#34;NumRuns to compare: &#34;+str(dataIndex))
                                for i in range(dataIndex):
                                        print(&#34;Stored data #%i:&#34; % i)
                                        print(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;][i])#, floatfmt=&#34;.10f&#34;))
                                        print(&#34;Received data #%i:&#34; % i)
                                        print(l_data[i])
                                        if not l_data[i] == self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;][i]:
                                                self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;NumRun &#39;+str(i+1)+&#39;: Received differing result set&#39;
                                                logging.debug(&#39;Received differing result set&#39;)
                                                keepResultsets = True
                                                break
                                                #raise ValueError(&#39;Received differing result set&#39;)
        except Exception as e:
                logging.exception(&#39;Caught an error: %s&#39; % str(e))
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;errors&#39;][c] = &#39;ERROR ({}) - {}&#39;.format(type(e).__name__, e)
                # store end time for query / connection
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;ends&#39;][c] = str(datetime.datetime.now())
                # benchmark is 0 due to error
                self.timerExecution.abortTimerRun()
                self.timerTransfer.abortTimerRun()
                if query.withConnect:
                        # we do benchmark connection time, so we connect every run
                        self.timerConnect.abortTimerRun()
                # this means ignore benchmark for this query/connection due to error
                self.timerExecution.cancelTimer()
                self.timerTransfer.cancelTimer()
                if query.withConnect:
                        # we do benchmark connection time, so we connect every run
                        self.timerConnect.cancelTimer()
                # this means store results even if error happend
                #self.timerExecution.abortTimer()
                #self.timerTransfer.abortTimer()
                # tqdm does not support break:
                # https://github.com/tqdm/tqdm/issues/613
                breakLoop = True
        finally:
                self.timerExecution.finishTimer()
                self.timerTransfer.finishTimer()
                if query.withConnect:
                        # we do benchmark connection time, so we connect every run
                        #self.disconnectDBMS(c)
                        self.timerConnect.finishTimer()
        if not keepResultsets:
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;resultSets&#39;][c] = []
        self.stopBenchmarkingQuery(numQuery)
        #if self.dbms[c].hasHardwareMetrics():
        #       metricsReporter = monitor.metrics(self)
        #       metricsReporter.generatePlotForQuery(numQuery)
        return True</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarks"><code class="name flex">
<span>def <span class="ident">runBenchmarks</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Runs benchmarks or possibly reruns specific benchmarks.
Generates reports.</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def runBenchmarks(self):
        &#34;&#34;&#34;
        Runs benchmarks or possibly reruns specific benchmarks.
        Generates reports.

        :return: returns nothing
        &#34;&#34;&#34;
        if self.working == &#39;query&#39;:
                self.runBenchmarksQuery()
        else:
                self.runBenchmarksConnection()
        if self.bBatch:
                # generate reports at the end only
                self.generateReportsAll()</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksConnection"><code class="name flex">
<span>def <span class="ident">runBenchmarksConnection</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Performs connectionwise benchmark runs.
Stores results and generates reports immediately after completion of a query (all runs).</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def runBenchmarksConnection(self):
        &#34;&#34;&#34;
        Performs connectionwise benchmark runs.
        Stores results and generates reports immediately after completion of a query (all runs).

        :return: returns nothing
        &#34;&#34;&#34;
        for c in sorted(self.dbms.keys()):
                for numQuery in range(1, len(self.queries)+1):
                        bBenchmarkDone = self.runBenchmark(numQuery, c)
                        # if benchmark has been done: store and generate reports
                        if bBenchmarkDone:
                                # store results
                                self.reporterStore.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
                                if not self.bBatch:
                                        # generate reports
                                        for r in self.reporter:
                                                r.init()
                                                r.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksQuery"><code class="name flex">
<span>def <span class="ident">runBenchmarksQuery</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Performs querywise benchmark runs.
Stores results and generates reports immediately after completion of a query (all connections, all runs).</p>
<p>:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def runBenchmarksQuery(self):
        &#34;&#34;&#34;
        Performs querywise benchmark runs.
        Stores results and generates reports immediately after completion of a query (all connections, all runs).

        :return: returns nothing
        &#34;&#34;&#34;
        for numQuery in range(1, len(self.queries)+1):
                if self.overwrite and not (self.fixedQuery is not None and self.fixedQuery != numQuery):# or (self.fixedConnection is not None and self.fixedConnection != connectionname):
                        # rerun this query
                        self.cleanProtocol(numQuery)
                for c in sorted(self.dbms.keys()):
                        # run benchmark, current query and connection
                        bBenchmarkDoneForThisQuery = self.runBenchmark(numQuery, c)
                        # if benchmark has been done: store and generate reports
                        if bBenchmarkDoneForThisQuery:
                                # store results
                                self.reporterStore.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])
                                if not self.bBatch:
                                        # generate reports
                                        for r in self.reporter:
                                                r.init()
                                                r.generate(numQuery, [self.timerExecution, self.timerTransfer, self.timerConnect])</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.runSingleBenchmark"><code class="name flex">
<span>def <span class="ident">runSingleBenchmark</span></span>(<span>self, numQuery, connectionname, numRun=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Runs a single benchmark run.
This generates the actual query string and sends it to the connected dbms.</p>
<p>:param numQuery: Number of query
:param connectionname: Name of connection
:param numRun: Number of benchmark run
:return: String of (SQL) query</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def runSingleBenchmark(self, numQuery, connectionname, numRun=0):
        &#34;&#34;&#34;
        Runs a single benchmark run.
        This generates the actual query string and sends it to the connected dbms.

        :param numQuery: Number of query
        :param connectionname: Name of connection
        :param numRun: Number of benchmark run
        :return: String of (SQL) query
        &#34;&#34;&#34;
        queryString = self.getQueryString(numQuery, connectionname=connectionname, numRun=numRun)
        inputConfig = [singleRunInput(0, queryString, self.queries[numQuery-1])]
        output = singleRun(self.dbms[connectionname].connectiondata, inputConfig, [0], connectionname, numQuery, None)
        return output</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.startBenchmarkingQuery"><code class="name flex">
<span>def <span class="ident">startBenchmarkingQuery</span></span>(<span>self, numQuery)</span>
</code></dt>
<dd>
<section class="desc"><p>Starts protocol for that specific query.
Generates parameters.</p>
<p>:param numQuery: Number of query to benchmark
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def startBenchmarkingQuery(self, numQuery):
        &#34;&#34;&#34;
        Starts protocol for that specific query.
        Generates parameters.

        :param numQuery: Number of query to benchmark
        :return: returns nothing
        &#34;&#34;&#34;
        if self.protocol[&#39;query&#39;][str(numQuery)][&#39;start&#39;] == &#34;&#34;:
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;start&#39;] = str(datetime.datetime.now())
        self.start_query = timer()
        q = self.queries[numQuery-1]
        query = tools.query(q)
        if len(query.parameter) &gt; 0 and len(self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;]) == 0:
                params = parameter.generateParameters(query.parameter, query.numRun)
                self.protocol[&#39;query&#39;][str(numQuery)][&#39;parameter&#39;] = params
        print(&#34;Benchmarking Q&#34;+str(numQuery)+&#39;: &#39;+query.title)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.statsToDataFrame"><code class="name flex">
<span>def <span class="ident">statsToDataFrame</span></span>(<span>self, numQuery, timer)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns statistics of a given query and timer as a DataFrame (rows=dbms, cols=statisticd).</p>
<p>:param numQuery: Number of query
:param timer: Timer object
:return: DataFrame of benchmark statistics</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def statsToDataFrame(self, numQuery, timer):
        &#34;&#34;&#34;
        Returns statistics of a given query and timer as a DataFrame (rows=dbms, cols=statisticd).

        :param numQuery: Number of query
        :param timer: Timer object
        :return: DataFrame of benchmark statistics
        &#34;&#34;&#34;
        dataframe = timer.statsToDataFrame(numQuery)
        # remove inactive connections
        dataframe = self.removeInactiveConnectionsFromDataframe(dataframe)
        # add factor column
        dataframe = tools.dataframehelper.addFactor(dataframe, self.queryconfig[&#39;factor&#39;])
        return dataframe</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.benchmarker.stopBenchmarkingQuery"><code class="name flex">
<span>def <span class="ident">stopBenchmarkingQuery</span></span>(<span>self, numQuery)</span>
</code></dt>
<dd>
<section class="desc"><p>Writes collected data to protocol for that specific query.</p>
<p>:param numQuery: Number of query to benchmark
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def stopBenchmarkingQuery(self, numQuery):
        &#34;&#34;&#34;
        Writes collected data to protocol for that specific query.

        :param numQuery: Number of query to benchmark
        :return: returns nothing
        &#34;&#34;&#34;
        end_query = timer()
        duration_query = end_query - self.start_query
        # add to protocol
        self.protocol[&#39;query&#39;][str(numQuery)][&#39;duration&#39;] += 1000.0*duration_query
        self.protocol[&#39;query&#39;][str(numQuery)][&#39;end&#39;] = str(datetime.datetime.now())</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector"><code class="flex name class">
<span>class <span class="ident">inspector</span></span>
<span>(</span><span>result_path, code)</span>
</code></dt>
<dd>
<section class="desc"><p>Class for inspecting done benchmarks</p>
<p>Construct a new 'benchmarker' object.
Allocated the reporters store (always called) and printer (if reports are to be generated).
A result folder is created if not existing already.</p>
<p>:param result_path: Path for storing result files. If None is given, a folder is created using time.
:param working: Process benchmarks query-wise or connection-wise
:param batch: Script is running in batch mode (more protocol-like output)
:param fixedQuery: Number of only query to be benchmarked
:param fixedConnection: Name of only connection to be benchmarked
:param anonymize: Anonymize all dbms
:param unanonymize: List of names of connections, which should not be anonymized despite of parameter anonymize
:param numProcesses: Number of parallel client processes. Global setting, can be overwritten by connection. If None, half of all available processes is taken
:return: returns nothing</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class inspector(benchmarker):
        &#34;&#34;&#34;
        Class for inspecting done benchmarks
        &#34;&#34;&#34;
        def __init__(self, result_path, code):
                benchmarker.__init__(self,result_path=result_path+&#34;/&#34;+code)
                self.getConfig()
                self.readResultfolder()
                print(&#34;Connections:&#34;)
                for c in self.connections:
                        print(c[&#39;name&#39;])
                print(&#34;Queries:&#34;)
                for i,q in enumerate(self.queries):
                        if &#39;active&#39; in q and q[&#39;active&#39;]:
                                print(str(i)+&#34;: Q&#34;+str(i+1)+&#34; = &#34;+q[&#39;title&#39;])
        def getResultSetCSV(self, query, connection):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_resultset_&#34;+connection+&#34;.csv&#34;
                if os.path.isfile(filename):
                        df = pd.read_csv(filename)
                        return df
                else:
                        print(&#34;No result found&#34;)
        def getResultSetDF(self, query, connection):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_resultset_&#34;+connection+&#34;.pickle&#34;
                if os.path.isfile(filename):
                        f = open(filename, &#34;rb&#34;)
                        result = pickle.load(f)
                        f.close()
                        return result
                else:
                        print(&#34;No result found&#34;)
        def getBenchmarks(self, query):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_execution_dataframe.pickle&#34;
                f = open(filename, &#34;rb&#34;)
                result = pickle.load(f)
                f.close()
                return result
        def getBenchmarksCSV(self, query, timer=&#34;execution&#34;):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_&#34;+timer+&#34;.csv&#34;
                df = pd.read_csv(filename)
                df_t = df.transpose()
                return df_t
        def getStatistics(self, query):
                filename=self.path+&#34;/query_&#34;+str(query)+&#34;_execution_statistics.pickle&#34;
                f = open(filename, &#34;rb&#34;)
                result = pickle.load(f)
                f.close()
                return result
        def listQueries(self):
                # list of active queries
                qs = tools.findSuccessfulQueriesAllDBMS(self, None, self.timers)[0]
                # index +1 for public addressing
                qs = [q+1 for q in qs]
                return qs
        def listConnections(self):
                # list of active dbms
                cs = [i for i,q in self.dbms.items() if q.connectiondata[&#39;active&#39;]]
                return cs
        def getSumPerTimer(self):
                dataframe, title = tools.dataframehelper.sumPerTimer(self, numQuery=None, timer=self.timers)
                return dataframe, title
        def getProdPerTimer(self):
                dataframe, title = tools.dataframehelper.multiplyPerTimer(self, numQuery=None, timer=self.timers)
                return dataframe, title
        def getTotalTime(self):
                dataframe, title = tools.dataframehelper.totalTimes(self)
                dataframe.loc[&#39;Total&#39;]= dataframe.sum()
                return dataframe, title
        def getError(self, query, connection=None):
                if connection is None:
                        return self.protocol[&#39;query&#39;][str(query)][&#39;errors&#39;]
                else:
                        return self.protocol[&#39;query&#39;][str(query)][&#39;errors&#39;][connection]
        def printErrors(self):
                for numQuery in range(1, len(self.queries)+1):
                        queryObject = tools.query(self.queries[numQuery-1])
                        if not queryObject.active:
                                continue
                        print(&#34;Q&#34;+str(numQuery))
                        print(self.getError(numQuery))
        def printDataStorageSizes(self):
                for numQuery in range(1, len(self.queries)+1):
                        queryObject = tools.query(self.queries[numQuery-1])
                        if not queryObject.active:
                                continue
                        print(&#34;Q&#34;+str(numQuery))
                        print(str(sys.getsizeof(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;]))+&#34; bytes&#34;)
        def readDataStorage(self, query, numRun=0):
                df = pd.DataFrame(self.protocol[&#39;query&#39;][str(query)][&#39;dataStorage&#39;][numRun])
                # set column names
                df.columns = df.iloc[0]
                # remove first row
                df = df[1:]
                return df
        def readResultSet(self, query, connection, numRun=0):
                df = pd.DataFrame(self.protocol[&#39;query&#39;][str(query)][&#39;resultSets&#39;][connection][numRun])
                # set column names
                df.columns = df.iloc[0]
                # remove first row
                df = df[1:]
                return df
        def getQueryObject(self, query):
                return tools.query(self.queries[query-1])
        def runIsolatedQuery(self, connectionname, queryString):
                query = {
                        &#39;numRun&#39;: 1,
                        &#39;withData&#39;: True,
                        &#39;query&#39;: queryString,
                        &#39;timer&#39;:
                        {
                                &#39;datatransfer&#39;:
                                {
                                        &#39;active&#39;: True,
                                        &#39;sorted&#39;: True,
                                        &#39;compare&#39;: &#39;result&#39;,
                                        &#39;store&#39;: &#39;dataframe&#39;,
                                        &#39;precision&#39;: 4,
                                },
                                &#39;connection&#39;:
                                {
                                        &#39;active&#39;: True,
                                }
                        }
                }
                input = singleRunInput(numRun=0, queryString=queryString, queryConfig=query)
                output = singleRun(connectiondata=self.dbms[connectionname].connectiondata,
                        inputConfig=[input],
                        numRuns=[0],
                        connectionname=connectionname,
                        numQuery=0,
                        path=None)
                df = pd.DataFrame.from_records(output.data)
                # set column names
                df.columns = df.iloc[0]
                # remove first row
                df = df[1:]
                output.dataframe = df
                return output
        def runAndStoreIsolatedQuery(self, connectionname, queryString, queryName=None):
                print(connectionname)
                output = self.runSingleQuery(connectionname, queryString)
                df = output.dataframe
                #print(df)
                if queryName is not None:
                        filename = self.path+&#34;query_resultset_&#34;+connectionname+&#34;_&#34;+queryName+&#34;.pickle&#34;
                        print(&#34;Store pickle of result set to &#34;+filename)
                        f = open(filename, &#34;wb&#34;)
                        pickle.dump(df, f)
                        f.close()
                return df
        def getIsolatedBenchmarks(self, connectionname, queryName):
                filename = self.path+&#34;query_resultset_&#34;+connectionname+&#34;_&#34;+queryName+&#34;.pickle&#34;
                f = open(filename, &#34;rb&#34;)
                result = pickle.load(f)
                f.close()
                return result</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dbmsbenchmarker.benchmarker.benchmarker" href="#dbmsbenchmarker.benchmarker.benchmarker">benchmarker</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="dbmsbenchmarker.benchmarker.inspector.getBenchmarks"><code class="name flex">
<span>def <span class="ident">getBenchmarks</span></span>(<span>self, query)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getBenchmarks(self, query):
        filename=self.path+&#34;/query_&#34;+str(query)+&#34;_execution_dataframe.pickle&#34;
        f = open(filename, &#34;rb&#34;)
        result = pickle.load(f)
        f.close()
        return result</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getBenchmarksCSV"><code class="name flex">
<span>def <span class="ident">getBenchmarksCSV</span></span>(<span>self, query, timer='execution')</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getBenchmarksCSV(self, query, timer=&#34;execution&#34;):
        filename=self.path+&#34;/query_&#34;+str(query)+&#34;_&#34;+timer+&#34;.csv&#34;
        df = pd.read_csv(filename)
        df_t = df.transpose()
        return df_t</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getError"><code class="name flex">
<span>def <span class="ident">getError</span></span>(<span>self, query, connection=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getError(self, query, connection=None):
        if connection is None:
                return self.protocol[&#39;query&#39;][str(query)][&#39;errors&#39;]
        else:
                return self.protocol[&#39;query&#39;][str(query)][&#39;errors&#39;][connection]</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getIsolatedBenchmarks"><code class="name flex">
<span>def <span class="ident">getIsolatedBenchmarks</span></span>(<span>self, connectionname, queryName)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getIsolatedBenchmarks(self, connectionname, queryName):
        filename = self.path+&#34;query_resultset_&#34;+connectionname+&#34;_&#34;+queryName+&#34;.pickle&#34;
        f = open(filename, &#34;rb&#34;)
        result = pickle.load(f)
        f.close()
        return result</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getProdPerTimer"><code class="name flex">
<span>def <span class="ident">getProdPerTimer</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getProdPerTimer(self):
        dataframe, title = tools.dataframehelper.multiplyPerTimer(self, numQuery=None, timer=self.timers)
        return dataframe, title</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getQueryObject"><code class="name flex">
<span>def <span class="ident">getQueryObject</span></span>(<span>self, query)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getQueryObject(self, query):
        return tools.query(self.queries[query-1])</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getResultSetCSV"><code class="name flex">
<span>def <span class="ident">getResultSetCSV</span></span>(<span>self, query, connection)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getResultSetCSV(self, query, connection):
        filename=self.path+&#34;/query_&#34;+str(query)+&#34;_resultset_&#34;+connection+&#34;.csv&#34;
        if os.path.isfile(filename):
                df = pd.read_csv(filename)
                return df
        else:
                print(&#34;No result found&#34;)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getResultSetDF"><code class="name flex">
<span>def <span class="ident">getResultSetDF</span></span>(<span>self, query, connection)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getResultSetDF(self, query, connection):
        filename=self.path+&#34;/query_&#34;+str(query)+&#34;_resultset_&#34;+connection+&#34;.pickle&#34;
        if os.path.isfile(filename):
                f = open(filename, &#34;rb&#34;)
                result = pickle.load(f)
                f.close()
                return result
        else:
                print(&#34;No result found&#34;)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getStatistics"><code class="name flex">
<span>def <span class="ident">getStatistics</span></span>(<span>self, query)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getStatistics(self, query):
        filename=self.path+&#34;/query_&#34;+str(query)+&#34;_execution_statistics.pickle&#34;
        f = open(filename, &#34;rb&#34;)
        result = pickle.load(f)
        f.close()
        return result</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getSumPerTimer"><code class="name flex">
<span>def <span class="ident">getSumPerTimer</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getSumPerTimer(self):
        dataframe, title = tools.dataframehelper.sumPerTimer(self, numQuery=None, timer=self.timers)
        return dataframe, title</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.getTotalTime"><code class="name flex">
<span>def <span class="ident">getTotalTime</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getTotalTime(self):
        dataframe, title = tools.dataframehelper.totalTimes(self)
        dataframe.loc[&#39;Total&#39;]= dataframe.sum()
        return dataframe, title</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.listConnections"><code class="name flex">
<span>def <span class="ident">listConnections</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def listConnections(self):
        # list of active dbms
        cs = [i for i,q in self.dbms.items() if q.connectiondata[&#39;active&#39;]]
        return cs</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.listQueries"><code class="name flex">
<span>def <span class="ident">listQueries</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def listQueries(self):
        # list of active queries
        qs = tools.findSuccessfulQueriesAllDBMS(self, None, self.timers)[0]
        # index +1 for public addressing
        qs = [q+1 for q in qs]
        return qs</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.printDataStorageSizes"><code class="name flex">
<span>def <span class="ident">printDataStorageSizes</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def printDataStorageSizes(self):
        for numQuery in range(1, len(self.queries)+1):
                queryObject = tools.query(self.queries[numQuery-1])
                if not queryObject.active:
                        continue
                print(&#34;Q&#34;+str(numQuery))
                print(str(sys.getsizeof(self.protocol[&#39;query&#39;][str(numQuery)][&#39;dataStorage&#39;]))+&#34; bytes&#34;)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.printErrors"><code class="name flex">
<span>def <span class="ident">printErrors</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def printErrors(self):
        for numQuery in range(1, len(self.queries)+1):
                queryObject = tools.query(self.queries[numQuery-1])
                if not queryObject.active:
                        continue
                print(&#34;Q&#34;+str(numQuery))
                print(self.getError(numQuery))</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.readDataStorage"><code class="name flex">
<span>def <span class="ident">readDataStorage</span></span>(<span>self, query, numRun=0)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def readDataStorage(self, query, numRun=0):
        df = pd.DataFrame(self.protocol[&#39;query&#39;][str(query)][&#39;dataStorage&#39;][numRun])
        # set column names
        df.columns = df.iloc[0]
        # remove first row
        df = df[1:]
        return df</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.readResultSet"><code class="name flex">
<span>def <span class="ident">readResultSet</span></span>(<span>self, query, connection, numRun=0)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def readResultSet(self, query, connection, numRun=0):
        df = pd.DataFrame(self.protocol[&#39;query&#39;][str(query)][&#39;resultSets&#39;][connection][numRun])
        # set column names
        df.columns = df.iloc[0]
        # remove first row
        df = df[1:]
        return df</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.runAndStoreIsolatedQuery"><code class="name flex">
<span>def <span class="ident">runAndStoreIsolatedQuery</span></span>(<span>self, connectionname, queryString, queryName=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def runAndStoreIsolatedQuery(self, connectionname, queryString, queryName=None):
        print(connectionname)
        output = self.runSingleQuery(connectionname, queryString)
        df = output.dataframe
        #print(df)
        if queryName is not None:
                filename = self.path+&#34;query_resultset_&#34;+connectionname+&#34;_&#34;+queryName+&#34;.pickle&#34;
                print(&#34;Store pickle of result set to &#34;+filename)
                f = open(filename, &#34;wb&#34;)
                pickle.dump(df, f)
                f.close()
        return df</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.inspector.runIsolatedQuery"><code class="name flex">
<span>def <span class="ident">runIsolatedQuery</span></span>(<span>self, connectionname, queryString)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def runIsolatedQuery(self, connectionname, queryString):
        query = {
                &#39;numRun&#39;: 1,
                &#39;withData&#39;: True,
                &#39;query&#39;: queryString,
                &#39;timer&#39;:
                {
                        &#39;datatransfer&#39;:
                        {
                                &#39;active&#39;: True,
                                &#39;sorted&#39;: True,
                                &#39;compare&#39;: &#39;result&#39;,
                                &#39;store&#39;: &#39;dataframe&#39;,
                                &#39;precision&#39;: 4,
                        },
                        &#39;connection&#39;:
                        {
                                &#39;active&#39;: True,
                        }
                }
        }
        input = singleRunInput(numRun=0, queryString=queryString, queryConfig=query)
        output = singleRun(connectiondata=self.dbms[connectionname].connectiondata,
                inputConfig=[input],
                numRuns=[0],
                connectionname=connectionname,
                numQuery=0,
                path=None)
        df = pd.DataFrame.from_records(output.data)
        # set column names
        df.columns = df.iloc[0]
        # remove first row
        df = df[1:]
        output.dataframe = df
        return output</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dbmsbenchmarker.benchmarker.benchmarker" href="#dbmsbenchmarker.benchmarker.benchmarker">benchmarker</a></b></code>:
<ul class="hlist">
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.benchmarksToDataFrame" href="#dbmsbenchmarker.benchmarker.benchmarker.benchmarksToDataFrame">benchmarksToDataFrame</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.cleanProtocol" href="#dbmsbenchmarker.benchmarker.benchmarker.cleanProtocol">cleanProtocol</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.clearBenchmarks" href="#dbmsbenchmarker.benchmarker.benchmarker.clearBenchmarks">clearBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.connectDBMS" href="#dbmsbenchmarker.benchmarker.benchmarker.connectDBMS">connectDBMS</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.connectDBMSAll" href="#dbmsbenchmarker.benchmarker.benchmarker.connectDBMSAll">connectDBMSAll</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.continueBenchmarks" href="#dbmsbenchmarker.benchmarker.benchmarker.continueBenchmarks">continueBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMS" href="#dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMS">disconnectDBMS</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMSAll" href="#dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMSAll">disconnectDBMSAll</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.generateReportsAll" href="#dbmsbenchmarker.benchmarker.benchmarker.generateReportsAll">generateReportsAll</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.generateSortedTotalRanking" href="#dbmsbenchmarker.benchmarker.benchmarker.generateSortedTotalRanking">generateSortedTotalRanking</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.getConfig" href="#dbmsbenchmarker.benchmarker.benchmarker.getConfig">getConfig</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.getConnectionsFromFile" href="#dbmsbenchmarker.benchmarker.benchmarker.getConnectionsFromFile">getConnectionsFromFile</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.getQueriesFromFile" href="#dbmsbenchmarker.benchmarker.benchmarker.getQueriesFromFile">getQueriesFromFile</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.getQueryString" href="#dbmsbenchmarker.benchmarker.benchmarker.getQueryString">getQueryString</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.readBenchmarks" href="#dbmsbenchmarker.benchmarker.benchmarker.readBenchmarks">readBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.readResultfolder" href="#dbmsbenchmarker.benchmarker.benchmarker.readResultfolder">readResultfolder</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.removeInactiveConnectionsFromDataframe" href="#dbmsbenchmarker.benchmarker.benchmarker.removeInactiveConnectionsFromDataframe">removeInactiveConnectionsFromDataframe</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runBenchmark" href="#dbmsbenchmarker.benchmarker.benchmarker.runBenchmark">runBenchmark</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarks" href="#dbmsbenchmarker.benchmarker.benchmarker.runBenchmarks">runBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksConnection" href="#dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksConnection">runBenchmarksConnection</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksQuery" href="#dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksQuery">runBenchmarksQuery</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runSingleBenchmark" href="#dbmsbenchmarker.benchmarker.benchmarker.runSingleBenchmark">runSingleBenchmark</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.startBenchmarkingQuery" href="#dbmsbenchmarker.benchmarker.benchmarker.startBenchmarkingQuery">startBenchmarkingQuery</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.statsToDataFrame" href="#dbmsbenchmarker.benchmarker.benchmarker.statsToDataFrame">statsToDataFrame</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.stopBenchmarkingQuery" href="#dbmsbenchmarker.benchmarker.benchmarker.stopBenchmarkingQuery">stopBenchmarkingQuery</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="dbmsbenchmarker.benchmarker.singleRunInput"><code class="flex name class">
<span>class <span class="ident">singleRunInput</span></span>
<span>(</span><span>numRun, queryString, queryConfig)</span>
</code></dt>
<dd>
<section class="desc"><p>Class for collecting info about a benchmark run</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class singleRunInput:
        &#34;&#34;&#34;
        Class for collecting info about a benchmark run
        &#34;&#34;&#34;
        def __init__(self, numRun, queryString, queryConfig):
                self.numRun = numRun
                self.queryString = queryString
                self.queryConfig = queryConfig</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.benchmarker.singleRunOutput"><code class="flex name class">
<span>class <span class="ident">singleRunOutput</span></span>
</code></dt>
<dd>
<section class="desc"><p>Class for collecting info about a benchmark run</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class singleRunOutput:
        &#34;&#34;&#34;
        Class for collecting info about a benchmark run
        &#34;&#34;&#34;
        def __init__(self):
                pass</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dbmsbenchmarker" href="index.html">dbmsbenchmarker</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dbmsbenchmarker.benchmarker.singleRun" href="#dbmsbenchmarker.benchmarker.singleRun">singleRun</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dbmsbenchmarker.benchmarker.benchmarker" href="#dbmsbenchmarker.benchmarker.benchmarker">benchmarker</a></code></h4>
<ul class="">
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.benchmarksToDataFrame" href="#dbmsbenchmarker.benchmarker.benchmarker.benchmarksToDataFrame">benchmarksToDataFrame</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.cleanProtocol" href="#dbmsbenchmarker.benchmarker.benchmarker.cleanProtocol">cleanProtocol</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.clearBenchmarks" href="#dbmsbenchmarker.benchmarker.benchmarker.clearBenchmarks">clearBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.connectDBMS" href="#dbmsbenchmarker.benchmarker.benchmarker.connectDBMS">connectDBMS</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.connectDBMSAll" href="#dbmsbenchmarker.benchmarker.benchmarker.connectDBMSAll">connectDBMSAll</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.continueBenchmarks" href="#dbmsbenchmarker.benchmarker.benchmarker.continueBenchmarks">continueBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMS" href="#dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMS">disconnectDBMS</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMSAll" href="#dbmsbenchmarker.benchmarker.benchmarker.disconnectDBMSAll">disconnectDBMSAll</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.generateReportsAll" href="#dbmsbenchmarker.benchmarker.benchmarker.generateReportsAll">generateReportsAll</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.generateSortedTotalRanking" href="#dbmsbenchmarker.benchmarker.benchmarker.generateSortedTotalRanking">generateSortedTotalRanking</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.getConfig" href="#dbmsbenchmarker.benchmarker.benchmarker.getConfig">getConfig</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.getConnectionsFromFile" href="#dbmsbenchmarker.benchmarker.benchmarker.getConnectionsFromFile">getConnectionsFromFile</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.getQueriesFromFile" href="#dbmsbenchmarker.benchmarker.benchmarker.getQueriesFromFile">getQueriesFromFile</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.getQueryString" href="#dbmsbenchmarker.benchmarker.benchmarker.getQueryString">getQueryString</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.readBenchmarks" href="#dbmsbenchmarker.benchmarker.benchmarker.readBenchmarks">readBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.readResultfolder" href="#dbmsbenchmarker.benchmarker.benchmarker.readResultfolder">readResultfolder</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.removeInactiveConnectionsFromDataframe" href="#dbmsbenchmarker.benchmarker.benchmarker.removeInactiveConnectionsFromDataframe">removeInactiveConnectionsFromDataframe</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runBenchmark" href="#dbmsbenchmarker.benchmarker.benchmarker.runBenchmark">runBenchmark</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarks" href="#dbmsbenchmarker.benchmarker.benchmarker.runBenchmarks">runBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksConnection" href="#dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksConnection">runBenchmarksConnection</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksQuery" href="#dbmsbenchmarker.benchmarker.benchmarker.runBenchmarksQuery">runBenchmarksQuery</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.runSingleBenchmark" href="#dbmsbenchmarker.benchmarker.benchmarker.runSingleBenchmark">runSingleBenchmark</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.startBenchmarkingQuery" href="#dbmsbenchmarker.benchmarker.benchmarker.startBenchmarkingQuery">startBenchmarkingQuery</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.statsToDataFrame" href="#dbmsbenchmarker.benchmarker.benchmarker.statsToDataFrame">statsToDataFrame</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.benchmarker.stopBenchmarkingQuery" href="#dbmsbenchmarker.benchmarker.benchmarker.stopBenchmarkingQuery">stopBenchmarkingQuery</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dbmsbenchmarker.benchmarker.inspector" href="#dbmsbenchmarker.benchmarker.inspector">inspector</a></code></h4>
<ul class="">
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getBenchmarks" href="#dbmsbenchmarker.benchmarker.inspector.getBenchmarks">getBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getBenchmarksCSV" href="#dbmsbenchmarker.benchmarker.inspector.getBenchmarksCSV">getBenchmarksCSV</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getError" href="#dbmsbenchmarker.benchmarker.inspector.getError">getError</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getIsolatedBenchmarks" href="#dbmsbenchmarker.benchmarker.inspector.getIsolatedBenchmarks">getIsolatedBenchmarks</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getProdPerTimer" href="#dbmsbenchmarker.benchmarker.inspector.getProdPerTimer">getProdPerTimer</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getQueryObject" href="#dbmsbenchmarker.benchmarker.inspector.getQueryObject">getQueryObject</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getResultSetCSV" href="#dbmsbenchmarker.benchmarker.inspector.getResultSetCSV">getResultSetCSV</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getResultSetDF" href="#dbmsbenchmarker.benchmarker.inspector.getResultSetDF">getResultSetDF</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getStatistics" href="#dbmsbenchmarker.benchmarker.inspector.getStatistics">getStatistics</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getSumPerTimer" href="#dbmsbenchmarker.benchmarker.inspector.getSumPerTimer">getSumPerTimer</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.getTotalTime" href="#dbmsbenchmarker.benchmarker.inspector.getTotalTime">getTotalTime</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.listConnections" href="#dbmsbenchmarker.benchmarker.inspector.listConnections">listConnections</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.listQueries" href="#dbmsbenchmarker.benchmarker.inspector.listQueries">listQueries</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.printDataStorageSizes" href="#dbmsbenchmarker.benchmarker.inspector.printDataStorageSizes">printDataStorageSizes</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.printErrors" href="#dbmsbenchmarker.benchmarker.inspector.printErrors">printErrors</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.readDataStorage" href="#dbmsbenchmarker.benchmarker.inspector.readDataStorage">readDataStorage</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.readResultSet" href="#dbmsbenchmarker.benchmarker.inspector.readResultSet">readResultSet</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.runAndStoreIsolatedQuery" href="#dbmsbenchmarker.benchmarker.inspector.runAndStoreIsolatedQuery">runAndStoreIsolatedQuery</a></code></li>
<li><code><a title="dbmsbenchmarker.benchmarker.inspector.runIsolatedQuery" href="#dbmsbenchmarker.benchmarker.inspector.runIsolatedQuery">runIsolatedQuery</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dbmsbenchmarker.benchmarker.singleRunInput" href="#dbmsbenchmarker.benchmarker.singleRunInput">singleRunInput</a></code></h4>
</li>
<li>
<h4><code><a title="dbmsbenchmarker.benchmarker.singleRunOutput" href="#dbmsbenchmarker.benchmarker.singleRunOutput">singleRunOutput</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.6.3</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>