<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.6.3" />
<title>dbmsbenchmarker.monitor API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dbmsbenchmarker.monitor</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>Source code</summary>
<pre><code class="python">import requests
import pandas as pd
from datetime import datetime
import matplotlib
import matplotlib.pyplot as plt
import csv
import os.path
import logging
from dbmsbenchmarker import benchmarker, tools
# https://www.robustperception.io/productive-prometheus-python-parsing

class metrics():
    metrics = {
        &#39;total_cpu_memory&#39;: {
            &#39;query&#39;: &#39;(node_memory_MemTotal_bytes-node_memory_MemFree_bytes-node_memory_Buffers_bytes-node_memory_Cached_bytes)/1024/1024&#39;,
            &#39;title&#39;: &#39;CPU Memory [MB]&#39;
        },
        &#39;total_cpu_memory_cached&#39;: {
            &#39;query&#39;: &#39;(node_memory_Cached_bytes)/1024/1024&#39;,
            &#39;title&#39;: &#39;CPU Memory Cached [MB]&#39;
        },
        &#39;total_cpu_util&#39;: {
            &#39;query&#39;: &#39;100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=&#34;idle&#34;}[5m])) * 100)&#39;,
            &#39;title&#39;: &#39;CPU Util [%]&#39;
        },
        &#39;total_gpu_util&#39;: {
            &#39;query&#39;: &#39;sum(dcgm_gpu_utilization)&#39;,
            &#39;title&#39;: &#39;GPU Util [%]&#39;
        },
        &#39;total_gpu_power&#39;: {
            &#39;query&#39;: &#39;sum(dcgm_power_usage)&#39;,
            &#39;title&#39;: &#39;GPU Power Usage [W]&#39;
        },
        &#39;total_gpu_memory&#39;: {
            &#39;query&#39;: &#39;sum(dcgm_fb_used)&#39;,
            &#39;title&#39;: &#39;GPU Memory [MB]&#39;
        },
    }
    latex = &#34;&#34;&#34;\\newpage\\subsubsection{{Hardware Metrics}}
    \\begin{{figure}}[h]
    \\centering
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_gpu_util.png}}
    \\end{{minipage}}
    \\hfill
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_gpu_power.png}}
    \\end{{minipage}}
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_gpu_memory.png}}
    \\end{{minipage}}
    \\hfill
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_cpu_util.png}}
    \\end{{minipage}}
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_cpu_memory_cached.png}}
    \\end{{minipage}}
    \\hfill
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_cpu_memory.png}}
    \\end{{minipage}}
  \\caption{{Query {queryNumber}: Server Hardware Metrics}}
\\end{{figure}}&#34;&#34;&#34;
    def __init__(self, benchmarks):
        self.step = 1
        self.benchmarker = benchmarks
    def getMetrics(self, metric,time_start, time_end, step=1):
        query = &#39;query_range?query=&#39;+metric[&#39;query&#39;]+&#39;&amp;start=&#39;+str(time_start)+&#39;&amp;end=&#39;+str(time_end)+&#39;&amp;step=&#39;+str(self.step)
        headers = {&#39;Authorization&#39;: self.token}
        r = requests.post(self.url+query, headers=headers)
        if len(r.json()[&#39;data&#39;][&#39;result&#39;]) &gt; 0:
            l = r.json()[&#39;data&#39;][&#39;result&#39;][0][&#39;values&#39;]
        else:
            l = [(time_start,0)]
        return l
    def metricsToDataframe(self, metric, values):
        df = pd.DataFrame.from_records(values)
        df.columns = [&#39;time [s]&#39;, metric[&#39;title&#39;]]
        df.iloc[0:,0] = df.iloc[0:,0].map(int)
        minimum = df.iloc[0:,0].min()
        df.iloc[0:,0] = df.iloc[0:,0].map(lambda x: x-minimum)
        df = df.set_index(df.columns[0])
        df.iloc[0:,0] = df.iloc[0:,0].map(float)
        return df
    def saveMetricsDataframe(self, filename, df):
        csv = df.to_csv(index_label=False,index=False)
        # save
        csv_file = open(filename, &#34;w&#34;)
        csv_file.write(csv)
        csv_file.close()
    def loadMetricsDataframe(self, filename):
        df = pd.read_csv(filename)
        return df
    def generatePlots(self):
        for q,d in self.benchmarker.protocol[&#39;query&#39;].items():
            print(&#34;Hardware metrics for Q&#34;+str(q))
            self.generatePlotForQuery(q)
    def generateLatexForQuery(self, parameter):
        latex = &#34;\\newpage\\subsubsection{{Hardware Metrics}}\n\\begin{{figure}}[h]\n\\centering\n&#34;
        query = parameter[&#39;queryNumber&#39;]
        numPlots = 0
        for m, metric in metrics.metrics.items():
            plotfile = self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;.png&#39;
            if os.path.isfile(plotfile):
                latex += &#34;&#34;&#34;    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_&#34;&#34;&#34;+m+&#34;&#34;&#34;.png}}
    \\end{{minipage}}\n&#34;&#34;&#34;
                if not numPlots % 2:
                    latex += &#34;\\hfill\n&#34;
                numPlots = numPlots + 1
        if numPlots &gt; 0:
            latex += &#34;\\caption{{Query {queryNumber}: Server Hardware Metrics}}\\end{{figure}}&#34;
            return latex.format(**parameter)
        else:
            return &#34;&#34;
    def generatePlotForQuery(self, query):
        intervals = {}
        times = self.benchmarker.protocol[&#39;query&#39;][str(query)]
        for m, metric in metrics.metrics.items():
            logging.debug(&#34;Metric &#34;+m)
            df_all = None
            for c,t in times[&#34;starts&#34;].items():
                self.token = self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanatoken&#39;]
                self.url = self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanaurl&#39;]
                if self.benchmarker.dbms[c].connectiondata[&#39;active&#39;] and self.token and self.url:
                    logging.debug(&#34;Connection &#34;+c)
                    # this yields seconds
                    time_start = int(datetime.timestamp(datetime.strptime(times[&#34;starts&#34;][c],&#39;%Y-%m-%d %H:%M:%S.%f&#39;)))
                    time_end = int(datetime.timestamp(datetime.strptime(times[&#34;ends&#34;][c],&#39;%Y-%m-%d %H:%M:%S.%f&#39;)))
                    intervals[c] = time_end-time_start #+1# because of ceil()
                    add_interval = int(self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanaextend&#39;])
                    time_start = time_start - add_interval
                    time_end = time_end + add_interval
                    #print(time_end-time_start)
                    csvfile = self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;_&#39;+c+&#39;.csv&#39;
                    if os.path.isfile(csvfile) and not self.benchmarker.overwrite:
                        logging.debug(&#34;Data exists&#34;)
                        df = self.loadMetricsDataframe(csvfile)
                        df.columns=[c]
                    else:
                        values = self.getMetrics(metric,time_start, time_end)
                        df = self.metricsToDataframe(metric, values)
                        df.columns=[c]
                        self.saveMetricsDataframe(csvfile, df)
                    #print(df)
                    if df.empty or len(df.index)==1:
                        continue
                    if df_all is None:
                        df_all = df
                    else:
                        df_all = df_all.merge(df,how=&#39;outer&#39;, left_index=True,right_index=True)
                    #print(df_all)
            if df_all is None:
                continue
            df_all.columns = df_all.columns.map(tools.dbms.anonymizer)
            if add_interval &gt; 0:
                df_all.index = df_all.index.map(mapper=(lambda i: i-add_interval))
                #print(df_all.index)
            #print(df_all)
            title=metric[&#39;title&#39;]
            ax = df_all.plot(title=title)
            ax.set_ylim(bottom=0, top=df_all.max().max()*1.10)
            #plt.legend(title=&#34;Metric&#34;)
            if add_interval &gt; 0:
                plt.axvline(x=0, linestyle=&#34;--&#34;, color=&#34;black&#34;)
                list_of_colors = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key()[&#39;color&#39;]
                i = 0
                for c,end in intervals.items():
                    if self.benchmarker.dbms[c].getName() in df_all.columns:
                        plt.axvline(x=end, linestyle=&#34;--&#34;, color=list_of_colors[i])
                        i = i + 1
                #plt.axvline(x=len(df_all.index)-2*add_interval-1, linestyle=&#34;--&#34;, color=&#34;black&#34;)
            plt.ticklabel_format(useOffset=False)
            plt.savefig(self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;.png&#39;, bbox_inches=&#39;tight&#39;)
            plt.close()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dbmsbenchmarker.monitor.metrics"><code class="flex name class">
<span>class <span class="ident">metrics</span></span>
<span>(</span><span>benchmarks)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class metrics():
    metrics = {
        &#39;total_cpu_memory&#39;: {
            &#39;query&#39;: &#39;(node_memory_MemTotal_bytes-node_memory_MemFree_bytes-node_memory_Buffers_bytes-node_memory_Cached_bytes)/1024/1024&#39;,
            &#39;title&#39;: &#39;CPU Memory [MB]&#39;
        },
        &#39;total_cpu_memory_cached&#39;: {
            &#39;query&#39;: &#39;(node_memory_Cached_bytes)/1024/1024&#39;,
            &#39;title&#39;: &#39;CPU Memory Cached [MB]&#39;
        },
        &#39;total_cpu_util&#39;: {
            &#39;query&#39;: &#39;100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=&#34;idle&#34;}[5m])) * 100)&#39;,
            &#39;title&#39;: &#39;CPU Util [%]&#39;
        },
        &#39;total_gpu_util&#39;: {
            &#39;query&#39;: &#39;sum(dcgm_gpu_utilization)&#39;,
            &#39;title&#39;: &#39;GPU Util [%]&#39;
        },
        &#39;total_gpu_power&#39;: {
            &#39;query&#39;: &#39;sum(dcgm_power_usage)&#39;,
            &#39;title&#39;: &#39;GPU Power Usage [W]&#39;
        },
        &#39;total_gpu_memory&#39;: {
            &#39;query&#39;: &#39;sum(dcgm_fb_used)&#39;,
            &#39;title&#39;: &#39;GPU Memory [MB]&#39;
        },
    }
    latex = &#34;&#34;&#34;\\newpage\\subsubsection{{Hardware Metrics}}
    \\begin{{figure}}[h]
    \\centering
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_gpu_util.png}}
    \\end{{minipage}}
    \\hfill
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_gpu_power.png}}
    \\end{{minipage}}
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_gpu_memory.png}}
    \\end{{minipage}}
    \\hfill
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_cpu_util.png}}
    \\end{{minipage}}
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_cpu_memory_cached.png}}
    \\end{{minipage}}
    \\hfill
    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_total_cpu_memory.png}}
    \\end{{minipage}}
  \\caption{{Query {queryNumber}: Server Hardware Metrics}}
\\end{{figure}}&#34;&#34;&#34;
    def __init__(self, benchmarks):
        self.step = 1
        self.benchmarker = benchmarks
    def getMetrics(self, metric,time_start, time_end, step=1):
        query = &#39;query_range?query=&#39;+metric[&#39;query&#39;]+&#39;&amp;start=&#39;+str(time_start)+&#39;&amp;end=&#39;+str(time_end)+&#39;&amp;step=&#39;+str(self.step)
        headers = {&#39;Authorization&#39;: self.token}
        r = requests.post(self.url+query, headers=headers)
        if len(r.json()[&#39;data&#39;][&#39;result&#39;]) &gt; 0:
            l = r.json()[&#39;data&#39;][&#39;result&#39;][0][&#39;values&#39;]
        else:
            l = [(time_start,0)]
        return l
    def metricsToDataframe(self, metric, values):
        df = pd.DataFrame.from_records(values)
        df.columns = [&#39;time [s]&#39;, metric[&#39;title&#39;]]
        df.iloc[0:,0] = df.iloc[0:,0].map(int)
        minimum = df.iloc[0:,0].min()
        df.iloc[0:,0] = df.iloc[0:,0].map(lambda x: x-minimum)
        df = df.set_index(df.columns[0])
        df.iloc[0:,0] = df.iloc[0:,0].map(float)
        return df
    def saveMetricsDataframe(self, filename, df):
        csv = df.to_csv(index_label=False,index=False)
        # save
        csv_file = open(filename, &#34;w&#34;)
        csv_file.write(csv)
        csv_file.close()
    def loadMetricsDataframe(self, filename):
        df = pd.read_csv(filename)
        return df
    def generatePlots(self):
        for q,d in self.benchmarker.protocol[&#39;query&#39;].items():
            print(&#34;Hardware metrics for Q&#34;+str(q))
            self.generatePlotForQuery(q)
    def generateLatexForQuery(self, parameter):
        latex = &#34;\\newpage\\subsubsection{{Hardware Metrics}}\n\\begin{{figure}}[h]\n\\centering\n&#34;
        query = parameter[&#39;queryNumber&#39;]
        numPlots = 0
        for m, metric in metrics.metrics.items():
            plotfile = self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;.png&#39;
            if os.path.isfile(plotfile):
                latex += &#34;&#34;&#34;    \\begin{{minipage}}[t]{{0.45\\textwidth}}
        \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_&#34;&#34;&#34;+m+&#34;&#34;&#34;.png}}
    \\end{{minipage}}\n&#34;&#34;&#34;
                if not numPlots % 2:
                    latex += &#34;\\hfill\n&#34;
                numPlots = numPlots + 1
        if numPlots &gt; 0:
            latex += &#34;\\caption{{Query {queryNumber}: Server Hardware Metrics}}\\end{{figure}}&#34;
            return latex.format(**parameter)
        else:
            return &#34;&#34;
    def generatePlotForQuery(self, query):
        intervals = {}
        times = self.benchmarker.protocol[&#39;query&#39;][str(query)]
        for m, metric in metrics.metrics.items():
            logging.debug(&#34;Metric &#34;+m)
            df_all = None
            for c,t in times[&#34;starts&#34;].items():
                self.token = self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanatoken&#39;]
                self.url = self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanaurl&#39;]
                if self.benchmarker.dbms[c].connectiondata[&#39;active&#39;] and self.token and self.url:
                    logging.debug(&#34;Connection &#34;+c)
                    # this yields seconds
                    time_start = int(datetime.timestamp(datetime.strptime(times[&#34;starts&#34;][c],&#39;%Y-%m-%d %H:%M:%S.%f&#39;)))
                    time_end = int(datetime.timestamp(datetime.strptime(times[&#34;ends&#34;][c],&#39;%Y-%m-%d %H:%M:%S.%f&#39;)))
                    intervals[c] = time_end-time_start #+1# because of ceil()
                    add_interval = int(self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanaextend&#39;])
                    time_start = time_start - add_interval
                    time_end = time_end + add_interval
                    #print(time_end-time_start)
                    csvfile = self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;_&#39;+c+&#39;.csv&#39;
                    if os.path.isfile(csvfile) and not self.benchmarker.overwrite:
                        logging.debug(&#34;Data exists&#34;)
                        df = self.loadMetricsDataframe(csvfile)
                        df.columns=[c]
                    else:
                        values = self.getMetrics(metric,time_start, time_end)
                        df = self.metricsToDataframe(metric, values)
                        df.columns=[c]
                        self.saveMetricsDataframe(csvfile, df)
                    #print(df)
                    if df.empty or len(df.index)==1:
                        continue
                    if df_all is None:
                        df_all = df
                    else:
                        df_all = df_all.merge(df,how=&#39;outer&#39;, left_index=True,right_index=True)
                    #print(df_all)
            if df_all is None:
                continue
            df_all.columns = df_all.columns.map(tools.dbms.anonymizer)
            if add_interval &gt; 0:
                df_all.index = df_all.index.map(mapper=(lambda i: i-add_interval))
                #print(df_all.index)
            #print(df_all)
            title=metric[&#39;title&#39;]
            ax = df_all.plot(title=title)
            ax.set_ylim(bottom=0, top=df_all.max().max()*1.10)
            #plt.legend(title=&#34;Metric&#34;)
            if add_interval &gt; 0:
                plt.axvline(x=0, linestyle=&#34;--&#34;, color=&#34;black&#34;)
                list_of_colors = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key()[&#39;color&#39;]
                i = 0
                for c,end in intervals.items():
                    if self.benchmarker.dbms[c].getName() in df_all.columns:
                        plt.axvline(x=end, linestyle=&#34;--&#34;, color=list_of_colors[i])
                        i = i + 1
                #plt.axvline(x=len(df_all.index)-2*add_interval-1, linestyle=&#34;--&#34;, color=&#34;black&#34;)
            plt.ticklabel_format(useOffset=False)
            plt.savefig(self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;.png&#39;, bbox_inches=&#39;tight&#39;)
            plt.close()</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="dbmsbenchmarker.monitor.metrics.latex"><code class="name">var <span class="ident">latex</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="dbmsbenchmarker.monitor.metrics.metrics"><code class="name">var <span class="ident">metrics</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dbmsbenchmarker.monitor.metrics.generateLatexForQuery"><code class="name flex">
<span>def <span class="ident">generateLatexForQuery</span></span>(<span>self, parameter)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def generateLatexForQuery(self, parameter):
    latex = &#34;\\newpage\\subsubsection{{Hardware Metrics}}\n\\begin{{figure}}[h]\n\\centering\n&#34;
    query = parameter[&#39;queryNumber&#39;]
    numPlots = 0
    for m, metric in metrics.metrics.items():
        plotfile = self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;.png&#39;
        if os.path.isfile(plotfile):
            latex += &#34;&#34;&#34;    \\begin{{minipage}}[t]{{0.45\\textwidth}}
    \\includegraphics[height=0.9\\textwidth]{{query_{queryNumber}_metric_&#34;&#34;&#34;+m+&#34;&#34;&#34;.png}}
\\end{{minipage}}\n&#34;&#34;&#34;
            if not numPlots % 2:
                latex += &#34;\\hfill\n&#34;
            numPlots = numPlots + 1
    if numPlots &gt; 0:
        latex += &#34;\\caption{{Query {queryNumber}: Server Hardware Metrics}}\\end{{figure}}&#34;
        return latex.format(**parameter)
    else:
        return &#34;&#34;</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.monitor.metrics.generatePlotForQuery"><code class="name flex">
<span>def <span class="ident">generatePlotForQuery</span></span>(<span>self, query)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def generatePlotForQuery(self, query):
    intervals = {}
    times = self.benchmarker.protocol[&#39;query&#39;][str(query)]
    for m, metric in metrics.metrics.items():
        logging.debug(&#34;Metric &#34;+m)
        df_all = None
        for c,t in times[&#34;starts&#34;].items():
            self.token = self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanatoken&#39;]
            self.url = self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanaurl&#39;]
            if self.benchmarker.dbms[c].connectiondata[&#39;active&#39;] and self.token and self.url:
                logging.debug(&#34;Connection &#34;+c)
                # this yields seconds
                time_start = int(datetime.timestamp(datetime.strptime(times[&#34;starts&#34;][c],&#39;%Y-%m-%d %H:%M:%S.%f&#39;)))
                time_end = int(datetime.timestamp(datetime.strptime(times[&#34;ends&#34;][c],&#39;%Y-%m-%d %H:%M:%S.%f&#39;)))
                intervals[c] = time_end-time_start #+1# because of ceil()
                add_interval = int(self.benchmarker.dbms[c].connectiondata[&#39;monitoring&#39;][&#39;grafanaextend&#39;])
                time_start = time_start - add_interval
                time_end = time_end + add_interval
                #print(time_end-time_start)
                csvfile = self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;_&#39;+c+&#39;.csv&#39;
                if os.path.isfile(csvfile) and not self.benchmarker.overwrite:
                    logging.debug(&#34;Data exists&#34;)
                    df = self.loadMetricsDataframe(csvfile)
                    df.columns=[c]
                else:
                    values = self.getMetrics(metric,time_start, time_end)
                    df = self.metricsToDataframe(metric, values)
                    df.columns=[c]
                    self.saveMetricsDataframe(csvfile, df)
                #print(df)
                if df.empty or len(df.index)==1:
                    continue
                if df_all is None:
                    df_all = df
                else:
                    df_all = df_all.merge(df,how=&#39;outer&#39;, left_index=True,right_index=True)
                #print(df_all)
        if df_all is None:
            continue
        df_all.columns = df_all.columns.map(tools.dbms.anonymizer)
        if add_interval &gt; 0:
            df_all.index = df_all.index.map(mapper=(lambda i: i-add_interval))
            #print(df_all.index)
        #print(df_all)
        title=metric[&#39;title&#39;]
        ax = df_all.plot(title=title)
        ax.set_ylim(bottom=0, top=df_all.max().max()*1.10)
        #plt.legend(title=&#34;Metric&#34;)
        if add_interval &gt; 0:
            plt.axvline(x=0, linestyle=&#34;--&#34;, color=&#34;black&#34;)
            list_of_colors = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key()[&#39;color&#39;]
            i = 0
            for c,end in intervals.items():
                if self.benchmarker.dbms[c].getName() in df_all.columns:
                    plt.axvline(x=end, linestyle=&#34;--&#34;, color=list_of_colors[i])
                    i = i + 1
            #plt.axvline(x=len(df_all.index)-2*add_interval-1, linestyle=&#34;--&#34;, color=&#34;black&#34;)
        plt.ticklabel_format(useOffset=False)
        plt.savefig(self.benchmarker.path+&#39;/query_&#39;+str(query)+&#39;_metric_&#39;+str(m)+&#39;.png&#39;, bbox_inches=&#39;tight&#39;)
        plt.close()</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.monitor.metrics.generatePlots"><code class="name flex">
<span>def <span class="ident">generatePlots</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def generatePlots(self):
    for q,d in self.benchmarker.protocol[&#39;query&#39;].items():
        print(&#34;Hardware metrics for Q&#34;+str(q))
        self.generatePlotForQuery(q)</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.monitor.metrics.getMetrics"><code class="name flex">
<span>def <span class="ident">getMetrics</span></span>(<span>self, metric, time_start, time_end, step=1)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def getMetrics(self, metric,time_start, time_end, step=1):
    query = &#39;query_range?query=&#39;+metric[&#39;query&#39;]+&#39;&amp;start=&#39;+str(time_start)+&#39;&amp;end=&#39;+str(time_end)+&#39;&amp;step=&#39;+str(self.step)
    headers = {&#39;Authorization&#39;: self.token}
    r = requests.post(self.url+query, headers=headers)
    if len(r.json()[&#39;data&#39;][&#39;result&#39;]) &gt; 0:
        l = r.json()[&#39;data&#39;][&#39;result&#39;][0][&#39;values&#39;]
    else:
        l = [(time_start,0)]
    return l</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.monitor.metrics.loadMetricsDataframe"><code class="name flex">
<span>def <span class="ident">loadMetricsDataframe</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def loadMetricsDataframe(self, filename):
    df = pd.read_csv(filename)
    return df</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.monitor.metrics.metricsToDataframe"><code class="name flex">
<span>def <span class="ident">metricsToDataframe</span></span>(<span>self, metric, values)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def metricsToDataframe(self, metric, values):
    df = pd.DataFrame.from_records(values)
    df.columns = [&#39;time [s]&#39;, metric[&#39;title&#39;]]
    df.iloc[0:,0] = df.iloc[0:,0].map(int)
    minimum = df.iloc[0:,0].min()
    df.iloc[0:,0] = df.iloc[0:,0].map(lambda x: x-minimum)
    df = df.set_index(df.columns[0])
    df.iloc[0:,0] = df.iloc[0:,0].map(float)
    return df</code></pre>
</details>
</dd>
<dt id="dbmsbenchmarker.monitor.metrics.saveMetricsDataframe"><code class="name flex">
<span>def <span class="ident">saveMetricsDataframe</span></span>(<span>self, filename, df)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def saveMetricsDataframe(self, filename, df):
    csv = df.to_csv(index_label=False,index=False)
    # save
    csv_file = open(filename, &#34;w&#34;)
    csv_file.write(csv)
    csv_file.close()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dbmsbenchmarker" href="index.html">dbmsbenchmarker</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dbmsbenchmarker.monitor.metrics" href="#dbmsbenchmarker.monitor.metrics">metrics</a></code></h4>
<ul class="">
<li><code><a title="dbmsbenchmarker.monitor.metrics.generateLatexForQuery" href="#dbmsbenchmarker.monitor.metrics.generateLatexForQuery">generateLatexForQuery</a></code></li>
<li><code><a title="dbmsbenchmarker.monitor.metrics.generatePlotForQuery" href="#dbmsbenchmarker.monitor.metrics.generatePlotForQuery">generatePlotForQuery</a></code></li>
<li><code><a title="dbmsbenchmarker.monitor.metrics.generatePlots" href="#dbmsbenchmarker.monitor.metrics.generatePlots">generatePlots</a></code></li>
<li><code><a title="dbmsbenchmarker.monitor.metrics.getMetrics" href="#dbmsbenchmarker.monitor.metrics.getMetrics">getMetrics</a></code></li>
<li><code><a title="dbmsbenchmarker.monitor.metrics.latex" href="#dbmsbenchmarker.monitor.metrics.latex">latex</a></code></li>
<li><code><a title="dbmsbenchmarker.monitor.metrics.loadMetricsDataframe" href="#dbmsbenchmarker.monitor.metrics.loadMetricsDataframe">loadMetricsDataframe</a></code></li>
<li><code><a title="dbmsbenchmarker.monitor.metrics.metrics" href="#dbmsbenchmarker.monitor.metrics.metrics">metrics</a></code></li>
<li><code><a title="dbmsbenchmarker.monitor.metrics.metricsToDataframe" href="#dbmsbenchmarker.monitor.metrics.metricsToDataframe">metricsToDataframe</a></code></li>
<li><code><a title="dbmsbenchmarker.monitor.metrics.saveMetricsDataframe" href="#dbmsbenchmarker.monitor.metrics.saveMetricsDataframe">saveMetricsDataframe</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.6.3</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>